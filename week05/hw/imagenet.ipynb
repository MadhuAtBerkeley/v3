{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as opt\n",
    "\n",
    "import torch.utils.data\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.models as models\n",
    "from torch.optim.lr_scheduler import OneCycleLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f6aa373bef0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "#cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "START_EPOCH = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set the architecture to resnet 18 below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "model_names = sorted(name for name in models.__dict__\n",
    "    if name.islower() and not name.startswith(\"__\")\n",
    "    and callable(models.__dict__[name]))\n",
    "\n",
    "##########################\n",
    "ARCH = 'resnet18' # set the architecture to RESNET 18\n",
    "# please look up how to do that\n",
    "########################\n",
    "EPOCHS = 6\n",
    "LR = 0.1\n",
    "MOMENTUM = 0.9\n",
    "WEIGHT_DECAY = 3e-5\n",
    "PRINT_FREQ = 100\n",
    "TRAIN_BATCH=256\n",
    "VAL_BATCH=64\n",
    "WORKERS=6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAINDIR=\"/home/user1/work/w251/imageNet-ILSVRC2012/download_and_prepare_imagenet_dataset/train\"\n",
    "VALDIR=\"/home/user1/work/w251/imageNet-ILSVRC2012/download_and_prepare_imagenet_dataset/val\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check if cuda is available here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check if cuda is available in this cell\n",
    "# if it is not available, you should not go forward!\n",
    "\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assign your GPU below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign your GPU in this cell\n",
    "GPU = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set your active device to your GPU in this cell\n",
    "if torch.cuda.is_available():  \n",
    "  dev =  'cuda:{}'.format(GPU)\n",
    "else:  \n",
    "  dev = \"cpu\"  \n",
    "\n",
    "device = torch.device(dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# enable algorithm optimization\n",
    "cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fill in the heart of the train section below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader, model, criterion, optimizer, scheduler, epoch, device=torch.device('cpu')):\n",
    "    batch_time = AverageMeter('Time', ':6.3f')\n",
    "    data_time = AverageMeter('Data', ':6.3f')\n",
    "    losses = AverageMeter('Loss', ':.3e')\n",
    "    top1 = AverageMeter('Acc@1', ':6.2f')\n",
    "    top5 = AverageMeter('Acc@5', ':6.2f')\n",
    "    progress = ProgressMeter(\n",
    "        len(train_loader),\n",
    "        [batch_time, data_time, losses, top1, top5],\n",
    "        prefix=\"Epoch: [{}]\".format(epoch))\n",
    "\n",
    "    ######################\n",
    "    # switch model to train mode here\n",
    "    model.train()\n",
    "    ################\n",
    "\n",
    "    end = time.time()\n",
    "    for i, (images, target) in enumerate(train_loader):\n",
    "        # measure data loading time\n",
    "        data_time.update(time.time() - end)\n",
    "\n",
    "        #####################\n",
    "        # send the images to cuda device\n",
    "        images = images.cuda(GPU, non_blocking=True)\n",
    "        # send the target to cuda device\n",
    "        target = target.cuda(GPU, non_blocking=True)\n",
    "        \n",
    "        \n",
    "        # compute output\n",
    "        output = model(images)\n",
    "\n",
    "        # compute loss \n",
    "        loss = criterion(output, target)\n",
    "\n",
    "\n",
    "        # measure accuracy and record loss\n",
    "        acc1, acc5 = accuracy(output, target, topk=(1, 5))\n",
    "        losses.update(loss.item(), images.size(0))\n",
    "        top1.update(acc1[0], images.size(0))\n",
    "        top5.update(acc5[0], images.size(0))\n",
    "\n",
    "        # compute gradient and do SGD step\n",
    "        \n",
    "        #### zero out gradients in the optimier\n",
    "        ## optimizer ..??\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        ## backprop!\n",
    "        ### loss... ???\n",
    "        loss.backward()\n",
    "        \n",
    "        # update the weights!\n",
    "        ## optimier .. ??\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        if i % PRINT_FREQ == 0:\n",
    "            progress.display(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fill in the validate section below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(val_loader, model, criterion, device):\n",
    "    batch_time = AverageMeter('Time', ':6.3f')\n",
    "    losses = AverageMeter('Loss', ':.4e')\n",
    "    top1 = AverageMeter('Acc@1', ':6.2f')\n",
    "    top5 = AverageMeter('Acc@5', ':6.2f')\n",
    "    progress = ProgressMeter(\n",
    "        len(val_loader),\n",
    "        [batch_time, losses, top1, top5],\n",
    "        prefix='Test: ')\n",
    "\n",
    "    # switch to evaluate mode\n",
    "    # model ???\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        end = time.time()\n",
    "        for i, (images, target) in enumerate(val_loader):\n",
    "            \n",
    "            \n",
    "            ### send the images and target to cuda\n",
    "            images = images.to(device)\n",
    "            target = target.to(device)\n",
    "\n",
    "            # compute output\n",
    "            output = model(images)\n",
    "\n",
    "            # compute loss\n",
    "            loss  = criterion(output,target)\n",
    "\n",
    "\n",
    "            # measure accuracy and record loss\n",
    "            acc1, acc5 = accuracy(output, target, topk=(1, 5))\n",
    "            losses.update(loss.item(), images.size(0))\n",
    "            top1.update(acc1[0], images.size(0))\n",
    "            top5.update(acc5[0], images.size(0))\n",
    "\n",
    "            # measure elapsed time\n",
    "            batch_time.update(time.time() - end)\n",
    "            end = time.time()\n",
    "\n",
    "            if i % PRINT_FREQ == 0:\n",
    "                progress.display(i)\n",
    "\n",
    "        # TODO: this should also be done with the ProgressMeter\n",
    "        print(' * Acc@1 {top1.avg:.3f} Acc@5 {top5.avg:.3f}'\n",
    "              .format(top1=top1, top5=top5))\n",
    "\n",
    "    return top1.avg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self, name, fmt=':f'):\n",
    "        self.name = name\n",
    "        self.fmt = fmt\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "    def __str__(self):\n",
    "        fmtstr = '{name} {val' + self.fmt + '} ({avg' + self.fmt + '})'\n",
    "        return fmtstr.format(**self.__dict__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProgressMeter(object):\n",
    "    def __init__(self, num_batches, meters, prefix=\"\"):\n",
    "        self.batch_fmtstr = self._get_batch_fmtstr(num_batches)\n",
    "        self.meters = meters\n",
    "        self.prefix = prefix\n",
    "\n",
    "    def display(self, batch):\n",
    "        entries = [self.prefix + self.batch_fmtstr.format(batch)]\n",
    "        entries += [str(meter) for meter in self.meters]\n",
    "        print('\\t'.join(entries))\n",
    "\n",
    "    def _get_batch_fmtstr(self, num_batches):\n",
    "        num_digits = len(str(num_batches // 1))\n",
    "        fmt = '{:' + str(num_digits) + 'd}'\n",
    "        return '[' + fmt + '/' + fmt.format(num_batches) + ']'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(state, is_best, filename='./checkpoint.pth.tar'):\n",
    "    # save the model state!\n",
    "    # state ??? \n",
    "    torch.save(state, filename)\n",
    "    if is_best:\n",
    "        shutil.copyfile(filename, './model_best.pth.tar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(output, target, topk=(1,)):\n",
    "    \"\"\"Computes the accuracy over the k top predictions for the specified values of k\"\"\"\n",
    "    with torch.no_grad():\n",
    "        maxk = max(topk)\n",
    "        batch_size = target.size(0)\n",
    "\n",
    "        _, pred = output.topk(maxk, 1, True, True)\n",
    "        pred = pred.t()\n",
    "        correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "        res = []\n",
    "        for k in topk:\n",
    "            correct_k = correct[:k].reshape(-1).float().sum(0, keepdim=True)\n",
    "            res.append(correct_k.mul_(100.0 / batch_size))\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagenet_mean_RGB = [0.47889522, 0.47227842, 0.43047404]\n",
    "imagenet_std_RGB = [0.229, 0.224, 0.225]\n",
    "cinic_mean_RGB = [0.47889522, 0.47227842, 0.43047404]\n",
    "cinic_std_RGB = [0.24205776, 0.23828046, 0.25874835]\n",
    "cifar_mean_RGB = [0.4914, 0.4822, 0.4465]\n",
    "cifar_std_RGB = [0.2023, 0.1994, 0.2010]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 32\n",
    "IMG_SIZE = 224"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize the model using the architecture you selected above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Creating model 'resnet18'\n"
     ]
    }
   ],
   "source": [
    "# select the model\n",
    "print(\"=> Creating model '{}'\".format(ARCH))\n",
    "model = models.__dict__[ARCH]()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Send the model to the cuda device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# send the model to the cuda device..\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiate the loss to cross entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the cross-entropy loss\n",
    "criterion = nn.CrossEntropyLoss().cuda(GPU)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiate the optimizer to SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use SGD .. use the momentum and weight decay vars\n",
    "optimizer = opt.SGD(model.parameters(), lr=LR, momentum=0.9, weight_decay=WEIGHT_DECAY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create the learning rate scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use CosineAnnealingLR\n",
    "#scheduler =  torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=200)\n",
    "# Use Super Convergence                                                                           \n",
    "#scheduler = OneCycleLR(optimizer, max_lr=1.0, steps_per_epoch=len(train_loader), epochs=EPOCHS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the train dataset object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(IMG_SIZE),# padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(imagenet_mean_RGB, imagenet_std_RGB),\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = torchvision.datasets.ImageFolder(TRAINDIR, transform=transform_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the val dataset object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_val = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(IMG_SIZE),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(imagenet_mean_RGB, imagenet_std_RGB),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset = torchvision.datasets.ImageFolder(VALDIR, transform=transform_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the train dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill this in\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset,batch_size=256, num_workers=WORKERS, shuffle=True)\n",
    "#train_loader = torch.utils.data.DataLoader(train_dataset,batch_size=128, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill this in..\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset,  batch_size=64, num_workers=WORKERS, shuffle=True) \n",
    "#val_loader = torch.utils.data.DataLoader(val_dataset,  batch_size=128, shuffle=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_acc1 = 0\n",
    "# Use Super Convergence                                                                           \n",
    "scheduler = OneCycleLR(optimizer, max_lr=1.0, steps_per_epoch=len(train_loader), epochs=EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0][   0/5005]\tTime 33.021 (33.021)\tData 23.073 (23.073)\tLoss 7.060e+00 (7.060e+00)\tAcc@1   0.39 (  0.39)\tAcc@5   0.78 (  0.78)\n",
      "Epoch: [0][ 100/5005]\tTime  0.817 ( 3.044)\tData  0.095 ( 2.170)\tLoss 6.790e+00 (6.957e+00)\tAcc@1   0.39 (  0.25)\tAcc@5   0.78 (  1.12)\n",
      "Epoch: [0][ 200/5005]\tTime  1.106 ( 2.905)\tData  0.055 ( 2.078)\tLoss 6.552e+00 (6.830e+00)\tAcc@1   0.39 (  0.35)\tAcc@5   3.52 (  1.63)\n",
      "Epoch: [0][ 300/5005]\tTime  2.960 ( 2.850)\tData  2.330 ( 2.026)\tLoss 6.525e+00 (6.725e+00)\tAcc@1   0.78 (  0.55)\tAcc@5   1.95 (  2.13)\n",
      "Epoch: [0][ 400/5005]\tTime  2.023 ( 2.826)\tData  1.327 ( 1.999)\tLoss 6.260e+00 (6.629e+00)\tAcc@1   1.95 (  0.71)\tAcc@5   2.73 (  2.78)\n",
      "Epoch: [0][ 500/5005]\tTime  0.503 ( 2.801)\tData  0.037 ( 1.981)\tLoss 6.148e+00 (6.541e+00)\tAcc@1   1.56 (  0.89)\tAcc@5   6.25 (  3.39)\n",
      "Epoch: [0][ 600/5005]\tTime  2.231 ( 2.794)\tData  1.557 ( 1.981)\tLoss 5.786e+00 (6.459e+00)\tAcc@1   2.34 (  1.09)\tAcc@5  10.55 (  4.01)\n",
      "Epoch: [0][ 700/5005]\tTime  0.741 ( 2.793)\tData  0.048 ( 1.981)\tLoss 5.888e+00 (6.388e+00)\tAcc@1   3.12 (  1.31)\tAcc@5   9.77 (  4.65)\n",
      "Epoch: [0][ 800/5005]\tTime  0.887 ( 2.792)\tData  0.037 ( 1.979)\tLoss 5.908e+00 (6.324e+00)\tAcc@1   3.91 (  1.51)\tAcc@5   8.98 (  5.28)\n",
      "Epoch: [0][ 900/5005]\tTime  1.216 ( 2.787)\tData  0.491 ( 1.974)\tLoss 5.746e+00 (6.265e+00)\tAcc@1   3.12 (  1.71)\tAcc@5  12.89 (  5.89)\n",
      "Epoch: [0][1000/5005]\tTime  0.914 ( 2.788)\tData  0.053 ( 1.973)\tLoss 5.611e+00 (6.209e+00)\tAcc@1   3.91 (  1.91)\tAcc@5  12.89 (  6.48)\n",
      "Epoch: [0][1100/5005]\tTime  3.309 ( 2.781)\tData  2.560 ( 1.967)\tLoss 5.572e+00 (6.157e+00)\tAcc@1   4.69 (  2.12)\tAcc@5  12.89 (  7.09)\n",
      "Epoch: [0][1200/5005]\tTime  1.195 ( 2.779)\tData  0.404 ( 1.963)\tLoss 5.473e+00 (6.108e+00)\tAcc@1   5.47 (  2.32)\tAcc@5  14.45 (  7.66)\n",
      "Epoch: [0][1300/5005]\tTime  2.540 ( 2.778)\tData  1.790 ( 1.959)\tLoss 5.509e+00 (6.062e+00)\tAcc@1   4.69 (  2.54)\tAcc@5  14.45 (  8.24)\n",
      "Epoch: [0][1400/5005]\tTime  2.268 ( 2.779)\tData  1.456 ( 1.958)\tLoss 5.562e+00 (6.018e+00)\tAcc@1   5.86 (  2.76)\tAcc@5  16.02 (  8.78)\n",
      "Epoch: [0][1500/5005]\tTime  3.392 ( 2.780)\tData  2.598 ( 1.959)\tLoss 5.194e+00 (5.973e+00)\tAcc@1   7.42 (  3.00)\tAcc@5  20.31 (  9.37)\n",
      "Epoch: [0][1600/5005]\tTime  4.840 ( 2.782)\tData  4.292 ( 1.968)\tLoss 5.227e+00 (5.934e+00)\tAcc@1   6.25 (  3.21)\tAcc@5  16.41 (  9.92)\n",
      "Epoch: [0][1700/5005]\tTime  8.767 ( 2.785)\tData  8.005 ( 1.972)\tLoss 5.139e+00 (5.895e+00)\tAcc@1  12.50 (  3.40)\tAcc@5  23.05 ( 10.44)\n",
      "Epoch: [0][1800/5005]\tTime  0.783 ( 2.783)\tData  0.043 ( 1.969)\tLoss 5.311e+00 (5.856e+00)\tAcc@1   5.08 (  3.63)\tAcc@5  15.62 ( 11.00)\n",
      "Epoch: [0][1900/5005]\tTime  1.139 ( 2.782)\tData  0.089 ( 1.967)\tLoss 5.311e+00 (5.819e+00)\tAcc@1   8.20 (  3.85)\tAcc@5  17.97 ( 11.52)\n",
      "Epoch: [0][2000/5005]\tTime  7.886 ( 2.783)\tData  7.212 ( 1.967)\tLoss 4.975e+00 (5.783e+00)\tAcc@1   5.47 (  4.06)\tAcc@5  24.22 ( 12.05)\n",
      "Epoch: [0][2100/5005]\tTime  3.105 ( 2.782)\tData  2.138 ( 1.967)\tLoss 5.069e+00 (5.747e+00)\tAcc@1   7.42 (  4.29)\tAcc@5  24.61 ( 12.59)\n",
      "Epoch: [0][2200/5005]\tTime  1.251 ( 2.781)\tData  0.419 ( 1.966)\tLoss 5.092e+00 (5.711e+00)\tAcc@1  12.89 (  4.53)\tAcc@5  23.83 ( 13.14)\n",
      "Epoch: [0][2300/5005]\tTime  2.359 ( 2.782)\tData  1.691 ( 1.970)\tLoss 4.893e+00 (5.678e+00)\tAcc@1   9.77 (  4.76)\tAcc@5  26.95 ( 13.65)\n",
      "Epoch: [0][2400/5005]\tTime  1.045 ( 2.782)\tData  0.318 ( 1.967)\tLoss 4.890e+00 (5.644e+00)\tAcc@1   8.59 (  4.99)\tAcc@5  22.66 ( 14.18)\n",
      "Epoch: [0][2500/5005]\tTime  0.979 ( 2.781)\tData  0.084 ( 1.968)\tLoss 4.808e+00 (5.612e+00)\tAcc@1  10.55 (  5.23)\tAcc@5  28.12 ( 14.69)\n",
      "Epoch: [0][2600/5005]\tTime  3.451 ( 2.782)\tData  2.614 ( 1.969)\tLoss 4.760e+00 (5.580e+00)\tAcc@1  10.55 (  5.45)\tAcc@5  30.47 ( 15.21)\n",
      "Epoch: [0][2700/5005]\tTime  0.926 ( 2.781)\tData  0.128 ( 1.968)\tLoss 4.686e+00 (5.548e+00)\tAcc@1  12.89 (  5.70)\tAcc@5  30.47 ( 15.72)\n",
      "Epoch: [0][2800/5005]\tTime  0.815 ( 2.780)\tData  0.101 ( 1.968)\tLoss 4.735e+00 (5.517e+00)\tAcc@1  10.55 (  5.94)\tAcc@5  29.30 ( 16.23)\n",
      "Epoch: [0][2900/5005]\tTime  1.187 ( 2.781)\tData  0.411 ( 1.968)\tLoss 4.741e+00 (5.487e+00)\tAcc@1   9.38 (  6.18)\tAcc@5  26.17 ( 16.73)\n",
      "Epoch: [0][3000/5005]\tTime  0.853 ( 2.780)\tData  0.091 ( 1.968)\tLoss 4.702e+00 (5.457e+00)\tAcc@1  12.89 (  6.42)\tAcc@5  28.12 ( 17.24)\n",
      "Epoch: [0][3100/5005]\tTime  1.116 ( 2.779)\tData  0.149 ( 1.968)\tLoss 4.707e+00 (5.427e+00)\tAcc@1  14.84 (  6.66)\tAcc@5  29.69 ( 17.73)\n",
      "Epoch: [0][3200/5005]\tTime  4.886 ( 2.782)\tData  4.268 ( 1.973)\tLoss 4.339e+00 (5.399e+00)\tAcc@1  17.19 (  6.89)\tAcc@5  38.67 ( 18.20)\n",
      "Epoch: [0][3300/5005]\tTime  0.837 ( 2.781)\tData  0.082 ( 1.973)\tLoss 4.502e+00 (5.371e+00)\tAcc@1  16.41 (  7.14)\tAcc@5  36.33 ( 18.68)\n",
      "Epoch: [0][3400/5005]\tTime  0.765 ( 2.780)\tData  0.089 ( 1.974)\tLoss 4.353e+00 (5.343e+00)\tAcc@1  16.02 (  7.38)\tAcc@5  37.50 ( 19.15)\n",
      "Epoch: [0][3500/5005]\tTime  5.324 ( 2.781)\tData  4.455 ( 1.975)\tLoss 4.307e+00 (5.315e+00)\tAcc@1  17.19 (  7.63)\tAcc@5  38.67 ( 19.63)\n",
      "Epoch: [0][3600/5005]\tTime  5.565 ( 2.781)\tData  4.815 ( 1.975)\tLoss 4.541e+00 (5.289e+00)\tAcc@1  17.58 (  7.87)\tAcc@5  29.30 ( 20.09)\n",
      "Epoch: [0][3700/5005]\tTime  4.600 ( 2.781)\tData  3.975 ( 1.975)\tLoss 4.160e+00 (5.263e+00)\tAcc@1  20.70 (  8.11)\tAcc@5  44.53 ( 20.54)\n",
      "Epoch: [0][3800/5005]\tTime  1.062 ( 2.780)\tData  0.104 ( 1.973)\tLoss 4.150e+00 (5.237e+00)\tAcc@1  17.97 (  8.35)\tAcc@5  41.41 ( 20.99)\n",
      "Epoch: [0][3900/5005]\tTime  3.475 ( 2.780)\tData  2.738 ( 1.974)\tLoss 4.324e+00 (5.211e+00)\tAcc@1  14.84 (  8.59)\tAcc@5  35.94 ( 21.43)\n",
      "Epoch: [0][4000/5005]\tTime 14.359 ( 2.781)\tData 13.390 ( 1.976)\tLoss 4.180e+00 (5.186e+00)\tAcc@1  16.80 (  8.81)\tAcc@5  39.84 ( 21.87)\n",
      "Epoch: [0][4100/5005]\tTime  3.105 ( 2.780)\tData  2.389 ( 1.974)\tLoss 4.150e+00 (5.161e+00)\tAcc@1  19.14 (  9.06)\tAcc@5  38.28 ( 22.31)\n",
      "Epoch: [0][4200/5005]\tTime  2.208 ( 2.781)\tData  1.342 ( 1.974)\tLoss 4.126e+00 (5.137e+00)\tAcc@1  17.19 (  9.28)\tAcc@5  39.06 ( 22.73)\n",
      "Epoch: [0][4300/5005]\tTime  0.867 ( 2.780)\tData  0.097 ( 1.973)\tLoss 4.017e+00 (5.113e+00)\tAcc@1  20.70 (  9.50)\tAcc@5  41.41 ( 23.14)\n",
      "Epoch: [0][4400/5005]\tTime  1.621 ( 2.780)\tData  0.903 ( 1.972)\tLoss 4.248e+00 (5.090e+00)\tAcc@1  14.45 (  9.74)\tAcc@5  37.11 ( 23.55)\n",
      "Epoch: [0][4500/5005]\tTime  0.866 ( 2.780)\tData  0.084 ( 1.972)\tLoss 4.014e+00 (5.067e+00)\tAcc@1  21.88 (  9.97)\tAcc@5  44.92 ( 23.95)\n",
      "Epoch: [0][4600/5005]\tTime  0.963 ( 2.780)\tData  0.069 ( 1.971)\tLoss 4.278e+00 (5.045e+00)\tAcc@1  16.41 ( 10.19)\tAcc@5  36.33 ( 24.34)\n",
      "Epoch: [0][4700/5005]\tTime  1.049 ( 2.780)\tData  0.429 ( 1.972)\tLoss 4.226e+00 (5.024e+00)\tAcc@1  19.14 ( 10.41)\tAcc@5  41.80 ( 24.72)\n",
      "Epoch: [0][4800/5005]\tTime  0.845 ( 2.781)\tData  0.096 ( 1.972)\tLoss 3.869e+00 (5.002e+00)\tAcc@1  23.83 ( 10.61)\tAcc@5  42.58 ( 25.10)\n",
      "Epoch: [0][4900/5005]\tTime  6.002 ( 2.781)\tData  5.288 ( 1.972)\tLoss 3.744e+00 (4.982e+00)\tAcc@1  23.05 ( 10.83)\tAcc@5  49.22 ( 25.48)\n",
      "Epoch: [0][5000/5005]\tTime  0.647 ( 2.780)\tData  0.061 ( 1.971)\tLoss 3.900e+00 (4.961e+00)\tAcc@1  21.48 ( 11.05)\tAcc@5  45.31 ( 25.85)\n",
      "Test: [  0/782]\tTime  5.800 ( 5.800)\tLoss 3.9323e+00 (3.9323e+00)\tAcc@1  20.31 ( 20.31)\tAcc@5  39.06 ( 39.06)\n",
      "Test: [100/782]\tTime  0.289 ( 0.684)\tLoss 4.2349e+00 (3.8695e+00)\tAcc@1  21.88 ( 22.01)\tAcc@5  34.38 ( 45.53)\n",
      "Test: [200/782]\tTime  0.316 ( 0.666)\tLoss 4.5238e+00 (3.8542e+00)\tAcc@1  17.19 ( 21.98)\tAcc@5  35.94 ( 45.88)\n",
      "Test: [300/782]\tTime  0.330 ( 0.651)\tLoss 3.7237e+00 (3.8632e+00)\tAcc@1  14.06 ( 21.85)\tAcc@5  46.88 ( 45.40)\n",
      "Test: [400/782]\tTime  0.357 ( 0.649)\tLoss 3.9939e+00 (3.8750e+00)\tAcc@1  18.75 ( 21.66)\tAcc@5  45.31 ( 45.27)\n",
      "Test: [500/782]\tTime  0.356 ( 0.646)\tLoss 4.4227e+00 (3.8745e+00)\tAcc@1  17.19 ( 21.58)\tAcc@5  29.69 ( 45.24)\n",
      "Test: [600/782]\tTime  0.349 ( 0.645)\tLoss 3.7914e+00 (3.8757e+00)\tAcc@1  29.69 ( 21.67)\tAcc@5  48.44 ( 45.22)\n",
      "Test: [700/782]\tTime  0.333 ( 0.647)\tLoss 4.1054e+00 (3.8776e+00)\tAcc@1  17.19 ( 21.46)\tAcc@5  45.31 ( 45.16)\n",
      " * Acc@1 21.388 Acc@5 45.098\n",
      "lr: [0.60344271237111]\n",
      "Epoch: [1][   0/5005]\tTime 12.840 (12.840)\tData 11.409 (11.409)\tLoss 3.880e+00 (3.880e+00)\tAcc@1  22.66 ( 22.66)\tAcc@5  45.31 ( 45.31)\n",
      "Epoch: [1][ 100/5005]\tTime  1.131 ( 2.368)\tData  0.167 ( 1.150)\tLoss 3.857e+00 (3.904e+00)\tAcc@1  23.44 ( 22.23)\tAcc@5  48.44 ( 44.92)\n",
      "Epoch: [1][ 200/5005]\tTime  1.122 ( 2.330)\tData  0.111 ( 1.129)\tLoss 4.003e+00 (3.889e+00)\tAcc@1  20.31 ( 22.36)\tAcc@5  42.97 ( 45.16)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][ 300/5005]\tTime  1.366 ( 2.312)\tData  0.129 ( 1.127)\tLoss 3.919e+00 (3.884e+00)\tAcc@1  21.88 ( 22.50)\tAcc@5  42.97 ( 45.21)\n",
      "Epoch: [1][ 400/5005]\tTime  1.238 ( 2.302)\tData  0.098 ( 1.127)\tLoss 3.882e+00 (3.873e+00)\tAcc@1  23.05 ( 22.66)\tAcc@5  45.70 ( 45.41)\n",
      "Epoch: [1][ 500/5005]\tTime  1.446 ( 2.302)\tData  0.111 ( 1.135)\tLoss 4.093e+00 (3.865e+00)\tAcc@1  18.75 ( 22.81)\tAcc@5  40.62 ( 45.56)\n",
      "Epoch: [1][ 600/5005]\tTime  3.560 ( 2.303)\tData  2.488 ( 1.145)\tLoss 3.867e+00 (3.862e+00)\tAcc@1  23.05 ( 22.84)\tAcc@5  45.31 ( 45.61)\n",
      "Epoch: [1][ 700/5005]\tTime  2.752 ( 2.302)\tData  1.667 ( 1.155)\tLoss 3.919e+00 (3.853e+00)\tAcc@1  22.66 ( 23.01)\tAcc@5  44.92 ( 45.82)\n",
      "Epoch: [1][ 800/5005]\tTime  2.131 ( 2.303)\tData  0.992 ( 1.166)\tLoss 3.689e+00 (3.843e+00)\tAcc@1  26.17 ( 23.18)\tAcc@5  48.44 ( 45.99)\n",
      "Epoch: [1][ 900/5005]\tTime  2.051 ( 2.306)\tData  1.048 ( 1.176)\tLoss 3.418e+00 (3.834e+00)\tAcc@1  29.30 ( 23.29)\tAcc@5  53.12 ( 46.18)\n",
      "Epoch: [1][1000/5005]\tTime  1.290 ( 2.313)\tData  0.176 ( 1.192)\tLoss 3.855e+00 (3.826e+00)\tAcc@1  23.44 ( 23.44)\tAcc@5  51.17 ( 46.33)\n",
      "Epoch: [1][1100/5005]\tTime  2.019 ( 2.315)\tData  1.082 ( 1.205)\tLoss 3.343e+00 (3.818e+00)\tAcc@1  30.47 ( 23.55)\tAcc@5  53.12 ( 46.49)\n",
      "Epoch: [1][1200/5005]\tTime  1.111 ( 2.321)\tData  0.141 ( 1.220)\tLoss 3.782e+00 (3.812e+00)\tAcc@1  24.61 ( 23.65)\tAcc@5  48.05 ( 46.63)\n",
      "Epoch: [1][1300/5005]\tTime  3.802 ( 2.331)\tData  2.922 ( 1.241)\tLoss 3.720e+00 (3.803e+00)\tAcc@1  26.17 ( 23.75)\tAcc@5  52.34 ( 46.76)\n",
      "Epoch: [1][1400/5005]\tTime  1.929 ( 2.338)\tData  1.241 ( 1.256)\tLoss 3.708e+00 (3.794e+00)\tAcc@1  25.78 ( 23.87)\tAcc@5  48.44 ( 46.93)\n",
      "Epoch: [1][1500/5005]\tTime  1.026 ( 2.348)\tData  0.134 ( 1.273)\tLoss 3.589e+00 (3.786e+00)\tAcc@1  24.61 ( 23.97)\tAcc@5  52.73 ( 47.07)\n",
      "Epoch: [1][1600/5005]\tTime  3.030 ( 2.359)\tData  2.258 ( 1.294)\tLoss 3.596e+00 (3.780e+00)\tAcc@1  23.83 ( 24.07)\tAcc@5  49.61 ( 47.18)\n",
      "Epoch: [1][1700/5005]\tTime  2.566 ( 2.367)\tData  1.865 ( 1.311)\tLoss 3.652e+00 (3.771e+00)\tAcc@1  28.91 ( 24.18)\tAcc@5  50.78 ( 47.34)\n",
      "Epoch: [1][1800/5005]\tTime  0.874 ( 2.379)\tData  0.087 ( 1.329)\tLoss 3.406e+00 (3.764e+00)\tAcc@1  25.78 ( 24.27)\tAcc@5  54.30 ( 47.49)\n",
      "Epoch: [1][1900/5005]\tTime  4.689 ( 2.389)\tData  3.790 ( 1.346)\tLoss 3.691e+00 (3.756e+00)\tAcc@1  24.61 ( 24.41)\tAcc@5  48.44 ( 47.66)\n",
      "Epoch: [1][2000/5005]\tTime  7.208 ( 2.396)\tData  6.292 ( 1.361)\tLoss 3.729e+00 (3.748e+00)\tAcc@1  24.22 ( 24.54)\tAcc@5  48.83 ( 47.82)\n",
      "Epoch: [1][2100/5005]\tTime  1.287 ( 2.402)\tData  0.085 ( 1.372)\tLoss 3.528e+00 (3.742e+00)\tAcc@1  24.61 ( 24.64)\tAcc@5  50.00 ( 47.95)\n",
      "Epoch: [1][2200/5005]\tTime  1.913 ( 2.407)\tData  1.100 ( 1.384)\tLoss 3.755e+00 (3.735e+00)\tAcc@1  25.00 ( 24.73)\tAcc@5  47.66 ( 48.07)\n",
      "Epoch: [1][2300/5005]\tTime  0.915 ( 2.414)\tData  0.158 ( 1.398)\tLoss 3.771e+00 (3.727e+00)\tAcc@1  28.12 ( 24.84)\tAcc@5  50.00 ( 48.23)\n",
      "Epoch: [1][2400/5005]\tTime  1.120 ( 2.419)\tData  0.139 ( 1.407)\tLoss 3.394e+00 (3.720e+00)\tAcc@1  27.73 ( 24.96)\tAcc@5  55.47 ( 48.35)\n",
      "Epoch: [1][2500/5005]\tTime  2.597 ( 2.423)\tData  1.861 ( 1.416)\tLoss 3.374e+00 (3.714e+00)\tAcc@1  30.47 ( 25.05)\tAcc@5  54.30 ( 48.48)\n",
      "Epoch: [1][2600/5005]\tTime  0.863 ( 2.427)\tData  0.059 ( 1.425)\tLoss 3.609e+00 (3.706e+00)\tAcc@1  29.69 ( 25.16)\tAcc@5  51.56 ( 48.63)\n",
      "Epoch: [1][2700/5005]\tTime  1.277 ( 2.430)\tData  0.508 ( 1.433)\tLoss 3.502e+00 (3.699e+00)\tAcc@1  26.17 ( 25.25)\tAcc@5  55.08 ( 48.75)\n",
      "Epoch: [1][2800/5005]\tTime  4.560 ( 2.434)\tData  3.355 ( 1.442)\tLoss 3.424e+00 (3.694e+00)\tAcc@1  25.78 ( 25.33)\tAcc@5  50.78 ( 48.87)\n",
      "Epoch: [1][2900/5005]\tTime  0.929 ( 2.438)\tData  0.094 ( 1.448)\tLoss 3.468e+00 (3.688e+00)\tAcc@1  28.52 ( 25.41)\tAcc@5  51.56 ( 48.98)\n",
      "Epoch: [1][3000/5005]\tTime  3.310 ( 2.441)\tData  2.160 ( 1.455)\tLoss 3.330e+00 (3.681e+00)\tAcc@1  31.64 ( 25.49)\tAcc@5  51.17 ( 49.10)\n",
      "Epoch: [1][3100/5005]\tTime  0.800 ( 2.444)\tData  0.094 ( 1.461)\tLoss 3.315e+00 (3.675e+00)\tAcc@1  32.03 ( 25.59)\tAcc@5  59.38 ( 49.22)\n",
      "Epoch: [1][3200/5005]\tTime  1.408 ( 2.447)\tData  0.168 ( 1.466)\tLoss 3.515e+00 (3.668e+00)\tAcc@1  28.12 ( 25.70)\tAcc@5  49.22 ( 49.33)\n",
      "Epoch: [1][3300/5005]\tTime  0.903 ( 2.449)\tData  0.090 ( 1.470)\tLoss 3.468e+00 (3.663e+00)\tAcc@1  30.08 ( 25.79)\tAcc@5  53.91 ( 49.44)\n",
      "Epoch: [1][3400/5005]\tTime  1.377 ( 2.452)\tData  0.103 ( 1.475)\tLoss 3.439e+00 (3.656e+00)\tAcc@1  26.56 ( 25.88)\tAcc@5  50.39 ( 49.55)\n",
      "Epoch: [1][3500/5005]\tTime  3.214 ( 2.453)\tData  2.233 ( 1.479)\tLoss 3.442e+00 (3.650e+00)\tAcc@1  25.39 ( 25.97)\tAcc@5  55.47 ( 49.67)\n",
      "Epoch: [1][3600/5005]\tTime  3.724 ( 2.454)\tData  2.712 ( 1.484)\tLoss 3.559e+00 (3.644e+00)\tAcc@1  30.47 ( 26.07)\tAcc@5  49.22 ( 49.79)\n",
      "Epoch: [1][3700/5005]\tTime  1.062 ( 2.457)\tData  0.105 ( 1.488)\tLoss 3.406e+00 (3.639e+00)\tAcc@1  26.95 ( 26.14)\tAcc@5  57.03 ( 49.89)\n",
      "Epoch: [1][3800/5005]\tTime  1.914 ( 2.459)\tData  1.036 ( 1.492)\tLoss 3.368e+00 (3.634e+00)\tAcc@1  30.47 ( 26.21)\tAcc@5  55.47 ( 49.99)\n",
      "Epoch: [1][3900/5005]\tTime  1.069 ( 2.460)\tData  0.088 ( 1.495)\tLoss 3.304e+00 (3.629e+00)\tAcc@1  30.08 ( 26.31)\tAcc@5  55.08 ( 50.10)\n",
      "Epoch: [1][4000/5005]\tTime  7.262 ( 2.463)\tData  6.228 ( 1.499)\tLoss 3.540e+00 (3.622e+00)\tAcc@1  28.12 ( 26.41)\tAcc@5  55.08 ( 50.22)\n",
      "Epoch: [1][4100/5005]\tTime  4.817 ( 2.464)\tData  3.975 ( 1.503)\tLoss 3.456e+00 (3.617e+00)\tAcc@1  29.30 ( 26.49)\tAcc@5  53.52 ( 50.32)\n",
      "Epoch: [1][4200/5005]\tTime  1.067 ( 2.465)\tData  0.191 ( 1.505)\tLoss 3.232e+00 (3.612e+00)\tAcc@1  32.03 ( 26.58)\tAcc@5  55.47 ( 50.42)\n",
      "Epoch: [1][4300/5005]\tTime  1.071 ( 2.466)\tData  0.318 ( 1.508)\tLoss 3.271e+00 (3.607e+00)\tAcc@1  34.38 ( 26.65)\tAcc@5  56.64 ( 50.52)\n",
      "Epoch: [1][4400/5005]\tTime  3.113 ( 2.469)\tData  2.073 ( 1.511)\tLoss 3.314e+00 (3.601e+00)\tAcc@1  29.69 ( 26.74)\tAcc@5  55.08 ( 50.62)\n",
      "Epoch: [1][4500/5005]\tTime  1.117 ( 2.471)\tData  0.064 ( 1.514)\tLoss 3.413e+00 (3.596e+00)\tAcc@1  30.08 ( 26.82)\tAcc@5  51.56 ( 50.71)\n",
      "Epoch: [1][4600/5005]\tTime  6.026 ( 2.473)\tData  5.225 ( 1.517)\tLoss 3.116e+00 (3.591e+00)\tAcc@1  33.59 ( 26.90)\tAcc@5  62.50 ( 50.80)\n",
      "Epoch: [1][4700/5005]\tTime  3.052 ( 2.472)\tData  2.268 ( 1.518)\tLoss 3.658e+00 (3.586e+00)\tAcc@1  28.12 ( 26.98)\tAcc@5  52.73 ( 50.89)\n",
      "Epoch: [1][4800/5005]\tTime  0.893 ( 2.473)\tData  0.084 ( 1.521)\tLoss 3.154e+00 (3.581e+00)\tAcc@1  34.77 ( 27.06)\tAcc@5  58.59 ( 51.00)\n",
      "Epoch: [1][4900/5005]\tTime  1.688 ( 2.474)\tData  0.952 ( 1.523)\tLoss 3.308e+00 (3.576e+00)\tAcc@1  29.30 ( 27.13)\tAcc@5  55.86 ( 51.07)\n",
      "Epoch: [1][5000/5005]\tTime  0.626 ( 2.475)\tData  0.066 ( 1.525)\tLoss 3.360e+00 (3.572e+00)\tAcc@1  31.64 ( 27.20)\tAcc@5  58.20 ( 51.16)\n",
      "Test: [  0/782]\tTime  5.254 ( 5.254)\tLoss 3.1230e+00 (3.1230e+00)\tAcc@1  28.12 ( 28.12)\tAcc@5  59.38 ( 59.38)\n",
      "Test: [100/782]\tTime  0.294 ( 0.689)\tLoss 3.5482e+00 (3.1027e+00)\tAcc@1  28.12 ( 33.34)\tAcc@5  48.44 ( 59.64)\n",
      "Test: [200/782]\tTime  0.355 ( 0.654)\tLoss 3.2562e+00 (3.1080e+00)\tAcc@1  31.25 ( 33.28)\tAcc@5  59.38 ( 59.35)\n",
      "Test: [300/782]\tTime  1.403 ( 0.646)\tLoss 3.4535e+00 (3.1205e+00)\tAcc@1  25.00 ( 33.13)\tAcc@5  50.00 ( 59.11)\n",
      "Test: [400/782]\tTime  0.325 ( 0.638)\tLoss 2.8142e+00 (3.1136e+00)\tAcc@1  31.25 ( 33.13)\tAcc@5  70.31 ( 59.25)\n",
      "Test: [500/782]\tTime  1.041 ( 0.638)\tLoss 3.0672e+00 (3.1105e+00)\tAcc@1  31.25 ( 33.20)\tAcc@5  62.50 ( 59.39)\n",
      "Test: [600/782]\tTime  0.400 ( 0.638)\tLoss 3.0407e+00 (3.1171e+00)\tAcc@1  37.50 ( 33.19)\tAcc@5  60.94 ( 59.32)\n",
      "Test: [700/782]\tTime  0.335 ( 0.635)\tLoss 3.0681e+00 (3.1215e+00)\tAcc@1  32.81 ( 33.18)\tAcc@5  67.19 ( 59.23)\n",
      " * Acc@1 33.218 Acc@5 59.290\n",
      "lr: [0.9944042927758083]\n",
      "Epoch: [2][   0/5005]\tTime 13.462 (13.462)\tData 12.190 (12.190)\tLoss 3.109e+00 (3.109e+00)\tAcc@1  34.38 ( 34.38)\tAcc@5  57.03 ( 57.03)\n",
      "Epoch: [2][ 100/5005]\tTime  1.292 ( 2.376)\tData  0.164 ( 1.202)\tLoss 3.032e+00 (3.256e+00)\tAcc@1  39.84 ( 31.94)\tAcc@5  63.67 ( 57.08)\n",
      "Epoch: [2][ 200/5005]\tTime  1.972 ( 2.336)\tData  0.896 ( 1.168)\tLoss 3.287e+00 (3.273e+00)\tAcc@1  31.64 ( 31.56)\tAcc@5  54.69 ( 56.62)\n",
      "Epoch: [2][ 300/5005]\tTime  3.415 ( 2.316)\tData  2.223 ( 1.146)\tLoss 3.136e+00 (3.269e+00)\tAcc@1  33.98 ( 31.78)\tAcc@5  58.20 ( 56.69)\n",
      "Epoch: [2][ 400/5005]\tTime  4.675 ( 2.312)\tData  3.601 ( 1.146)\tLoss 3.424e+00 (3.272e+00)\tAcc@1  30.47 ( 31.81)\tAcc@5  54.69 ( 56.71)\n",
      "Epoch: [2][ 500/5005]\tTime  1.025 ( 2.311)\tData  0.090 ( 1.149)\tLoss 3.395e+00 (3.270e+00)\tAcc@1  29.69 ( 31.83)\tAcc@5  56.25 ( 56.72)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [2][ 600/5005]\tTime  2.668 ( 2.313)\tData  1.430 ( 1.160)\tLoss 3.530e+00 (3.272e+00)\tAcc@1  28.12 ( 31.81)\tAcc@5  51.56 ( 56.66)\n",
      "Epoch: [2][ 700/5005]\tTime  5.588 ( 2.316)\tData  4.480 ( 1.170)\tLoss 3.445e+00 (3.271e+00)\tAcc@1  29.69 ( 31.80)\tAcc@5  53.12 ( 56.69)\n",
      "Epoch: [2][ 800/5005]\tTime  1.924 ( 2.329)\tData  0.253 ( 1.186)\tLoss 3.248e+00 (3.273e+00)\tAcc@1  35.55 ( 31.77)\tAcc@5  57.81 ( 56.68)\n",
      "Epoch: [2][ 900/5005]\tTime  2.586 ( 2.353)\tData  1.305 ( 1.196)\tLoss 3.233e+00 (3.272e+00)\tAcc@1  32.42 ( 31.82)\tAcc@5  55.86 ( 56.72)\n",
      "Epoch: [2][1000/5005]\tTime  1.501 ( 2.368)\tData  0.186 ( 1.208)\tLoss 3.316e+00 (3.272e+00)\tAcc@1  29.69 ( 31.81)\tAcc@5  58.20 ( 56.73)\n",
      "Epoch: [2][1100/5005]\tTime  1.218 ( 2.369)\tData  0.195 ( 1.222)\tLoss 3.079e+00 (3.271e+00)\tAcc@1  35.55 ( 31.83)\tAcc@5  62.50 ( 56.76)\n",
      "Epoch: [2][1200/5005]\tTime  3.602 ( 2.373)\tData  2.546 ( 1.239)\tLoss 3.481e+00 (3.271e+00)\tAcc@1  26.56 ( 31.84)\tAcc@5  52.34 ( 56.73)\n",
      "Epoch: [2][1300/5005]\tTime  1.271 ( 2.376)\tData  0.308 ( 1.254)\tLoss 2.962e+00 (3.269e+00)\tAcc@1  36.33 ( 31.86)\tAcc@5  64.45 ( 56.77)\n",
      "Epoch: [2][1400/5005]\tTime  1.252 ( 2.384)\tData  0.160 ( 1.274)\tLoss 3.253e+00 (3.267e+00)\tAcc@1  33.98 ( 31.91)\tAcc@5  55.47 ( 56.81)\n",
      "Epoch: [2][1500/5005]\tTime  5.851 ( 2.388)\tData  4.895 ( 1.291)\tLoss 3.342e+00 (3.264e+00)\tAcc@1  27.73 ( 31.95)\tAcc@5  56.64 ( 56.85)\n",
      "Epoch: [2][1600/5005]\tTime  0.934 ( 2.394)\tData  0.097 ( 1.309)\tLoss 3.339e+00 (3.262e+00)\tAcc@1  33.98 ( 31.97)\tAcc@5  56.25 ( 56.89)\n",
      "Epoch: [2][1700/5005]\tTime  3.173 ( 2.403)\tData  2.385 ( 1.331)\tLoss 3.093e+00 (3.260e+00)\tAcc@1  33.59 ( 32.03)\tAcc@5  56.64 ( 56.93)\n",
      "Epoch: [2][1800/5005]\tTime  1.062 ( 2.409)\tData  0.346 ( 1.348)\tLoss 3.131e+00 (3.257e+00)\tAcc@1  34.77 ( 32.07)\tAcc@5  60.16 ( 56.96)\n",
      "Epoch: [2][1900/5005]\tTime  5.773 ( 2.418)\tData  5.009 ( 1.366)\tLoss 3.241e+00 (3.256e+00)\tAcc@1  31.64 ( 32.08)\tAcc@5  57.03 ( 56.99)\n",
      "Epoch: [2][2000/5005]\tTime  0.902 ( 2.422)\tData  0.089 ( 1.380)\tLoss 3.185e+00 (3.253e+00)\tAcc@1  35.55 ( 32.13)\tAcc@5  58.98 ( 57.04)\n",
      "Epoch: [2][2100/5005]\tTime  7.638 ( 2.430)\tData  6.817 ( 1.394)\tLoss 3.085e+00 (3.251e+00)\tAcc@1  33.98 ( 32.16)\tAcc@5  61.33 ( 57.06)\n",
      "Epoch: [2][2200/5005]\tTime  1.043 ( 2.434)\tData  0.078 ( 1.404)\tLoss 3.082e+00 (3.249e+00)\tAcc@1  34.77 ( 32.21)\tAcc@5  58.59 ( 57.12)\n",
      "Epoch: [2][2300/5005]\tTime  7.528 ( 2.439)\tData  6.536 ( 1.415)\tLoss 3.189e+00 (3.246e+00)\tAcc@1  32.81 ( 32.27)\tAcc@5  56.25 ( 57.17)\n",
      "Epoch: [2][2400/5005]\tTime  0.906 ( 2.442)\tData  0.136 ( 1.423)\tLoss 3.024e+00 (3.245e+00)\tAcc@1  41.02 ( 32.28)\tAcc@5  61.33 ( 57.19)\n",
      "Epoch: [2][2500/5005]\tTime  1.100 ( 2.446)\tData  0.093 ( 1.432)\tLoss 3.122e+00 (3.243e+00)\tAcc@1  36.72 ( 32.32)\tAcc@5  60.94 ( 57.23)\n",
      "Epoch: [2][2600/5005]\tTime  2.029 ( 2.449)\tData  1.167 ( 1.440)\tLoss 3.379e+00 (3.240e+00)\tAcc@1  29.69 ( 32.36)\tAcc@5  53.52 ( 57.27)\n",
      "Epoch: [2][2700/5005]\tTime  0.873 ( 2.454)\tData  0.106 ( 1.449)\tLoss 3.227e+00 (3.238e+00)\tAcc@1  32.42 ( 32.39)\tAcc@5  57.03 ( 57.31)\n",
      "Epoch: [2][2800/5005]\tTime  1.002 ( 2.456)\tData  0.117 ( 1.454)\tLoss 3.153e+00 (3.236e+00)\tAcc@1  33.59 ( 32.43)\tAcc@5  59.38 ( 57.36)\n",
      "Epoch: [2][2900/5005]\tTime  2.564 ( 2.458)\tData  1.660 ( 1.460)\tLoss 2.986e+00 (3.234e+00)\tAcc@1  35.94 ( 32.47)\tAcc@5  58.20 ( 57.40)\n",
      "Epoch: [2][3000/5005]\tTime  2.354 ( 2.460)\tData  1.172 ( 1.466)\tLoss 3.180e+00 (3.231e+00)\tAcc@1  33.20 ( 32.51)\tAcc@5  58.59 ( 57.45)\n",
      "Epoch: [2][3100/5005]\tTime  2.994 ( 2.464)\tData  1.888 ( 1.472)\tLoss 3.146e+00 (3.228e+00)\tAcc@1  33.98 ( 32.57)\tAcc@5  57.81 ( 57.50)\n",
      "Epoch: [2][3200/5005]\tTime  1.215 ( 2.467)\tData  0.196 ( 1.478)\tLoss 3.213e+00 (3.227e+00)\tAcc@1  32.81 ( 32.59)\tAcc@5  57.81 ( 57.53)\n",
      "Epoch: [2][3300/5005]\tTime  6.157 ( 2.470)\tData  5.252 ( 1.483)\tLoss 3.140e+00 (3.224e+00)\tAcc@1  33.98 ( 32.64)\tAcc@5  62.89 ( 57.58)\n",
      "Epoch: [2][3400/5005]\tTime  1.300 ( 2.472)\tData  0.206 ( 1.488)\tLoss 3.137e+00 (3.221e+00)\tAcc@1  32.42 ( 32.68)\tAcc@5  59.38 ( 57.63)\n",
      "Epoch: [2][3500/5005]\tTime  1.483 ( 2.473)\tData  0.552 ( 1.490)\tLoss 3.221e+00 (3.219e+00)\tAcc@1  34.38 ( 32.73)\tAcc@5  58.98 ( 57.67)\n",
      "Epoch: [2][3600/5005]\tTime  8.194 ( 2.477)\tData  7.351 ( 1.496)\tLoss 3.347e+00 (3.216e+00)\tAcc@1  32.03 ( 32.77)\tAcc@5  52.73 ( 57.71)\n",
      "Epoch: [2][3700/5005]\tTime  0.944 ( 2.478)\tData  0.075 ( 1.499)\tLoss 3.055e+00 (3.214e+00)\tAcc@1  37.50 ( 32.81)\tAcc@5  61.33 ( 57.75)\n",
      "Epoch: [2][3800/5005]\tTime  0.850 ( 2.478)\tData  0.080 ( 1.502)\tLoss 3.324e+00 (3.212e+00)\tAcc@1  29.69 ( 32.84)\tAcc@5  56.64 ( 57.79)\n",
      "Epoch: [2][3900/5005]\tTime  1.083 ( 2.481)\tData  0.317 ( 1.506)\tLoss 2.909e+00 (3.211e+00)\tAcc@1  36.72 ( 32.87)\tAcc@5  64.84 ( 57.82)\n",
      "Epoch: [2][4000/5005]\tTime  1.062 ( 2.482)\tData  0.143 ( 1.509)\tLoss 3.140e+00 (3.208e+00)\tAcc@1  36.72 ( 32.92)\tAcc@5  57.42 ( 57.87)\n",
      "Epoch: [2][4100/5005]\tTime  0.825 ( 2.483)\tData  0.078 ( 1.513)\tLoss 3.050e+00 (3.206e+00)\tAcc@1  35.16 ( 32.95)\tAcc@5  62.89 ( 57.90)\n",
      "Epoch: [2][4200/5005]\tTime  1.131 ( 2.486)\tData  0.070 ( 1.516)\tLoss 3.029e+00 (3.204e+00)\tAcc@1  32.81 ( 33.00)\tAcc@5  62.11 ( 57.94)\n",
      "Epoch: [2][4300/5005]\tTime  0.888 ( 2.487)\tData  0.105 ( 1.518)\tLoss 3.230e+00 (3.201e+00)\tAcc@1  30.08 ( 33.02)\tAcc@5  59.77 ( 57.98)\n",
      "Epoch: [2][4400/5005]\tTime  1.231 ( 2.488)\tData  0.085 ( 1.520)\tLoss 3.028e+00 (3.199e+00)\tAcc@1  36.72 ( 33.07)\tAcc@5  63.28 ( 58.02)\n",
      "Epoch: [2][4500/5005]\tTime  2.207 ( 2.489)\tData  1.283 ( 1.524)\tLoss 3.322e+00 (3.197e+00)\tAcc@1  28.12 ( 33.09)\tAcc@5  55.86 ( 58.05)\n",
      "Epoch: [2][4600/5005]\tTime  6.684 ( 2.490)\tData  5.765 ( 1.526)\tLoss 3.161e+00 (3.195e+00)\tAcc@1  29.30 ( 33.12)\tAcc@5  58.20 ( 58.09)\n",
      "Epoch: [2][4700/5005]\tTime  0.841 ( 2.490)\tData  0.075 ( 1.527)\tLoss 3.256e+00 (3.193e+00)\tAcc@1  33.98 ( 33.17)\tAcc@5  59.38 ( 58.13)\n",
      "Epoch: [2][4800/5005]\tTime  0.798 ( 2.492)\tData  0.096 ( 1.531)\tLoss 3.175e+00 (3.191e+00)\tAcc@1  32.81 ( 33.19)\tAcc@5  56.64 ( 58.17)\n",
      "Epoch: [2][4900/5005]\tTime  0.882 ( 2.492)\tData  0.102 ( 1.532)\tLoss 3.000e+00 (3.189e+00)\tAcc@1  36.72 ( 33.21)\tAcc@5  65.23 ( 58.19)\n",
      "Epoch: [2][5000/5005]\tTime  1.006 ( 2.493)\tData  0.146 ( 1.534)\tLoss 3.289e+00 (3.187e+00)\tAcc@1  30.86 ( 33.25)\tAcc@5  58.59 ( 58.23)\n",
      "Test: [  0/782]\tTime  4.708 ( 4.708)\tLoss 3.1876e+00 (3.1876e+00)\tAcc@1  34.38 ( 34.38)\tAcc@5  68.75 ( 68.75)\n",
      "Test: [100/782]\tTime  0.377 ( 0.668)\tLoss 3.4346e+00 (2.9228e+00)\tAcc@1  31.25 ( 36.37)\tAcc@5  59.38 ( 62.44)\n",
      "Test: [200/782]\tTime  0.344 ( 0.646)\tLoss 3.0128e+00 (2.9246e+00)\tAcc@1  32.81 ( 36.68)\tAcc@5  68.75 ( 62.84)\n",
      "Test: [300/782]\tTime  1.717 ( 0.643)\tLoss 2.9481e+00 (2.9336e+00)\tAcc@1  40.62 ( 36.54)\tAcc@5  59.38 ( 62.76)\n",
      "Test: [400/782]\tTime  0.328 ( 0.636)\tLoss 2.5321e+00 (2.9350e+00)\tAcc@1  39.06 ( 36.32)\tAcc@5  71.88 ( 62.77)\n",
      "Test: [500/782]\tTime  0.452 ( 0.638)\tLoss 3.0841e+00 (2.9333e+00)\tAcc@1  35.94 ( 36.35)\tAcc@5  57.81 ( 62.81)\n",
      "Test: [600/782]\tTime  0.641 ( 0.630)\tLoss 3.1262e+00 (2.9267e+00)\tAcc@1  35.94 ( 36.48)\tAcc@5  64.06 ( 62.99)\n",
      "Test: [700/782]\tTime  0.327 ( 0.632)\tLoss 3.0842e+00 (2.9307e+00)\tAcc@1  37.50 ( 36.37)\tAcc@5  57.81 ( 62.93)\n",
      " * Acc@1 36.428 Acc@5 62.990\n",
      "lr: [0.8116872282665173]\n",
      "Epoch: [3][   0/5005]\tTime 13.738 (13.738)\tData 12.419 (12.419)\tLoss 2.729e+00 (2.729e+00)\tAcc@1  42.58 ( 42.58)\tAcc@5  65.23 ( 65.23)\n",
      "Epoch: [3][ 100/5005]\tTime  1.275 ( 2.366)\tData  0.092 ( 1.179)\tLoss 3.183e+00 (3.043e+00)\tAcc@1  37.11 ( 35.25)\tAcc@5  55.86 ( 60.76)\n",
      "Epoch: [3][ 200/5005]\tTime  4.243 ( 2.332)\tData  3.244 ( 1.143)\tLoss 3.067e+00 (3.033e+00)\tAcc@1  32.81 ( 35.32)\tAcc@5  59.38 ( 60.92)\n",
      "Epoch: [3][ 300/5005]\tTime  3.784 ( 2.308)\tData  2.507 ( 1.131)\tLoss 3.071e+00 (3.036e+00)\tAcc@1  35.16 ( 35.34)\tAcc@5  64.45 ( 61.01)\n",
      "Epoch: [3][ 400/5005]\tTime  1.591 ( 2.345)\tData  0.214 ( 1.140)\tLoss 3.009e+00 (3.034e+00)\tAcc@1  37.11 ( 35.57)\tAcc@5  60.16 ( 61.01)\n",
      "Epoch: [3][ 500/5005]\tTime  6.589 ( 2.375)\tData  5.340 ( 1.152)\tLoss 3.164e+00 (3.032e+00)\tAcc@1  32.03 ( 35.57)\tAcc@5  57.81 ( 61.02)\n",
      "Epoch: [3][ 600/5005]\tTime  4.243 ( 2.375)\tData  3.153 ( 1.154)\tLoss 2.721e+00 (3.032e+00)\tAcc@1  41.41 ( 35.55)\tAcc@5  69.14 ( 61.04)\n",
      "Epoch: [3][ 700/5005]\tTime  2.164 ( 2.368)\tData  1.165 ( 1.165)\tLoss 2.914e+00 (3.034e+00)\tAcc@1  38.28 ( 35.54)\tAcc@5  62.89 ( 61.05)\n",
      "Epoch: [3][ 800/5005]\tTime  2.884 ( 2.361)\tData  1.743 ( 1.173)\tLoss 2.889e+00 (3.031e+00)\tAcc@1  37.89 ( 35.65)\tAcc@5  63.67 ( 61.05)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [3][ 900/5005]\tTime  3.109 ( 2.359)\tData  1.874 ( 1.184)\tLoss 3.095e+00 (3.032e+00)\tAcc@1  33.59 ( 35.68)\tAcc@5  59.38 ( 61.03)\n",
      "Epoch: [3][1000/5005]\tTime  1.300 ( 2.363)\tData  0.082 ( 1.198)\tLoss 3.072e+00 (3.031e+00)\tAcc@1  37.50 ( 35.70)\tAcc@5  59.38 ( 61.06)\n",
      "Epoch: [3][1100/5005]\tTime  3.738 ( 2.368)\tData  2.625 ( 1.215)\tLoss 2.941e+00 (3.029e+00)\tAcc@1  35.16 ( 35.74)\tAcc@5  63.67 ( 61.09)\n",
      "Epoch: [3][1200/5005]\tTime  2.166 ( 2.369)\tData  1.033 ( 1.229)\tLoss 3.024e+00 (3.031e+00)\tAcc@1  39.06 ( 35.71)\tAcc@5  61.33 ( 61.07)\n",
      "Epoch: [3][1300/5005]\tTime  6.913 ( 2.377)\tData  5.722 ( 1.249)\tLoss 2.938e+00 (3.028e+00)\tAcc@1  39.45 ( 35.79)\tAcc@5  62.50 ( 61.12)\n",
      "Epoch: [3][1400/5005]\tTime  2.170 ( 2.380)\tData  1.366 ( 1.262)\tLoss 2.936e+00 (3.026e+00)\tAcc@1  41.41 ( 35.83)\tAcc@5  61.72 ( 61.15)\n",
      "Epoch: [3][1500/5005]\tTime  4.710 ( 2.388)\tData  3.695 ( 1.283)\tLoss 2.921e+00 (3.024e+00)\tAcc@1  34.38 ( 35.86)\tAcc@5  62.11 ( 61.19)\n",
      "Epoch: [3][1600/5005]\tTime  1.440 ( 2.395)\tData  0.766 ( 1.300)\tLoss 3.348e+00 (3.023e+00)\tAcc@1  25.39 ( 35.88)\tAcc@5  55.47 ( 61.21)\n",
      "Epoch: [3][1700/5005]\tTime  0.787 ( 2.404)\tData  0.101 ( 1.320)\tLoss 2.888e+00 (3.022e+00)\tAcc@1  41.02 ( 35.90)\tAcc@5  60.55 ( 61.20)\n",
      "Epoch: [3][1800/5005]\tTime  1.034 ( 2.411)\tData  0.187 ( 1.336)\tLoss 2.863e+00 (3.021e+00)\tAcc@1  36.72 ( 35.90)\tAcc@5  62.89 ( 61.23)\n",
      "Epoch: [3][1900/5005]\tTime  2.112 ( 2.418)\tData  1.194 ( 1.352)\tLoss 3.062e+00 (3.019e+00)\tAcc@1  30.86 ( 35.94)\tAcc@5  63.28 ( 61.24)\n",
      "Epoch: [3][2000/5005]\tTime  1.275 ( 2.424)\tData  0.220 ( 1.364)\tLoss 3.125e+00 (3.018e+00)\tAcc@1  33.20 ( 35.98)\tAcc@5  61.33 ( 61.25)\n",
      "Epoch: [3][2100/5005]\tTime  4.605 ( 2.431)\tData  3.870 ( 1.379)\tLoss 3.110e+00 (3.016e+00)\tAcc@1  32.81 ( 36.00)\tAcc@5  56.25 ( 61.29)\n",
      "Epoch: [3][2200/5005]\tTime  5.566 ( 2.438)\tData  4.445 ( 1.392)\tLoss 2.950e+00 (3.014e+00)\tAcc@1  36.72 ( 36.04)\tAcc@5  61.72 ( 61.31)\n",
      "Epoch: [3][2300/5005]\tTime  1.717 ( 2.441)\tData  0.617 ( 1.401)\tLoss 2.831e+00 (3.013e+00)\tAcc@1  35.55 ( 36.08)\tAcc@5  66.02 ( 61.33)\n",
      "Epoch: [3][2400/5005]\tTime  1.206 ( 2.446)\tData  0.522 ( 1.410)\tLoss 3.052e+00 (3.012e+00)\tAcc@1  35.16 ( 36.11)\tAcc@5  63.28 ( 61.35)\n",
      "Epoch: [3][2500/5005]\tTime  3.289 ( 2.451)\tData  2.368 ( 1.420)\tLoss 2.748e+00 (3.010e+00)\tAcc@1  38.67 ( 36.16)\tAcc@5  64.06 ( 61.38)\n",
      "Epoch: [3][2600/5005]\tTime  0.852 ( 2.454)\tData  0.138 ( 1.428)\tLoss 3.216e+00 (3.008e+00)\tAcc@1  32.81 ( 36.18)\tAcc@5  56.25 ( 61.40)\n",
      "Epoch: [3][2700/5005]\tTime  5.421 ( 2.459)\tData  4.666 ( 1.437)\tLoss 3.005e+00 (3.006e+00)\tAcc@1  39.84 ( 36.22)\tAcc@5  61.33 ( 61.43)\n",
      "Epoch: [3][2800/5005]\tTime  4.040 ( 2.462)\tData  3.047 ( 1.445)\tLoss 2.912e+00 (3.004e+00)\tAcc@1  33.59 ( 36.25)\tAcc@5  62.11 ( 61.47)\n",
      "Epoch: [3][2900/5005]\tTime  6.590 ( 2.466)\tData  5.813 ( 1.453)\tLoss 2.855e+00 (3.003e+00)\tAcc@1  36.72 ( 36.28)\tAcc@5  62.11 ( 61.50)\n",
      "Epoch: [3][3000/5005]\tTime  3.982 ( 2.469)\tData  3.134 ( 1.458)\tLoss 3.127e+00 (3.001e+00)\tAcc@1  33.98 ( 36.31)\tAcc@5  57.81 ( 61.52)\n",
      "Epoch: [3][3100/5005]\tTime  0.919 ( 2.472)\tData  0.107 ( 1.463)\tLoss 3.062e+00 (2.999e+00)\tAcc@1  35.55 ( 36.36)\tAcc@5  59.77 ( 61.56)\n",
      "Epoch: [3][3200/5005]\tTime  1.529 ( 2.475)\tData  0.746 ( 1.469)\tLoss 2.960e+00 (2.997e+00)\tAcc@1  37.11 ( 36.41)\tAcc@5  61.33 ( 61.59)\n",
      "Epoch: [3][3300/5005]\tTime  1.371 ( 2.477)\tData  0.587 ( 1.474)\tLoss 2.950e+00 (2.995e+00)\tAcc@1  36.33 ( 36.44)\tAcc@5  61.33 ( 61.61)\n",
      "Epoch: [3][3400/5005]\tTime  3.348 ( 2.479)\tData  2.498 ( 1.480)\tLoss 2.918e+00 (2.994e+00)\tAcc@1  39.84 ( 36.46)\tAcc@5  63.67 ( 61.63)\n",
      "Epoch: [3][3500/5005]\tTime  1.909 ( 2.481)\tData  1.055 ( 1.485)\tLoss 2.739e+00 (2.992e+00)\tAcc@1  37.50 ( 36.50)\tAcc@5  64.45 ( 61.67)\n",
      "Epoch: [3][3600/5005]\tTime  2.215 ( 2.482)\tData  1.558 ( 1.489)\tLoss 2.937e+00 (2.989e+00)\tAcc@1  38.28 ( 36.56)\tAcc@5  63.67 ( 61.72)\n",
      "Epoch: [3][3700/5005]\tTime  2.963 ( 2.484)\tData  2.223 ( 1.493)\tLoss 2.945e+00 (2.987e+00)\tAcc@1  38.67 ( 36.59)\tAcc@5  64.06 ( 61.76)\n",
      "Epoch: [3][3800/5005]\tTime  3.413 ( 2.486)\tData  2.690 ( 1.497)\tLoss 2.890e+00 (2.985e+00)\tAcc@1  36.72 ( 36.62)\tAcc@5  63.67 ( 61.80)\n",
      "Epoch: [3][3900/5005]\tTime  2.745 ( 2.488)\tData  1.825 ( 1.501)\tLoss 2.875e+00 (2.983e+00)\tAcc@1  39.06 ( 36.65)\tAcc@5  63.28 ( 61.83)\n",
      "Epoch: [3][4000/5005]\tTime  0.921 ( 2.489)\tData  0.186 ( 1.504)\tLoss 2.786e+00 (2.981e+00)\tAcc@1  37.50 ( 36.68)\tAcc@5  64.45 ( 61.86)\n",
      "Epoch: [3][4100/5005]\tTime  4.156 ( 2.491)\tData  3.332 ( 1.507)\tLoss 2.846e+00 (2.979e+00)\tAcc@1  36.33 ( 36.73)\tAcc@5  61.33 ( 61.90)\n",
      "Epoch: [3][4200/5005]\tTime  0.848 ( 2.493)\tData  0.103 ( 1.511)\tLoss 2.934e+00 (2.977e+00)\tAcc@1  37.50 ( 36.76)\tAcc@5  63.67 ( 61.93)\n",
      "Epoch: [3][4300/5005]\tTime  9.229 ( 2.495)\tData  8.485 ( 1.516)\tLoss 3.036e+00 (2.975e+00)\tAcc@1  35.16 ( 36.80)\tAcc@5  57.42 ( 61.96)\n",
      "Epoch: [3][4400/5005]\tTime  2.824 ( 2.495)\tData  1.944 ( 1.518)\tLoss 2.955e+00 (2.973e+00)\tAcc@1  37.50 ( 36.83)\tAcc@5  62.11 ( 62.00)\n",
      "Epoch: [3][4500/5005]\tTime  1.118 ( 2.496)\tData  0.096 ( 1.520)\tLoss 2.941e+00 (2.971e+00)\tAcc@1  35.55 ( 36.86)\tAcc@5  63.67 ( 62.03)\n",
      "Epoch: [3][4600/5005]\tTime  1.073 ( 2.498)\tData  0.098 ( 1.524)\tLoss 2.736e+00 (2.969e+00)\tAcc@1  40.62 ( 36.89)\tAcc@5  67.19 ( 62.07)\n",
      "Epoch: [3][4700/5005]\tTime  5.072 ( 2.500)\tData  4.279 ( 1.526)\tLoss 3.043e+00 (2.967e+00)\tAcc@1  33.20 ( 36.93)\tAcc@5  61.33 ( 62.10)\n",
      "Epoch: [3][4800/5005]\tTime  0.829 ( 2.500)\tData  0.081 ( 1.528)\tLoss 2.762e+00 (2.965e+00)\tAcc@1  39.84 ( 36.96)\tAcc@5  65.23 ( 62.13)\n",
      "Epoch: [3][4900/5005]\tTime  1.065 ( 2.501)\tData  0.098 ( 1.531)\tLoss 2.958e+00 (2.964e+00)\tAcc@1  37.11 ( 37.00)\tAcc@5  64.45 ( 62.16)\n",
      "Epoch: [3][5000/5005]\tTime  1.763 ( 2.502)\tData  1.436 ( 1.533)\tLoss 2.666e+00 (2.962e+00)\tAcc@1  43.36 ( 37.03)\tAcc@5  67.58 ( 62.19)\n",
      "Test: [  0/782]\tTime  5.363 ( 5.363)\tLoss 2.9279e+00 (2.9279e+00)\tAcc@1  34.38 ( 34.38)\tAcc@5  57.81 ( 57.81)\n",
      "Test: [100/782]\tTime  0.410 ( 0.667)\tLoss 2.7815e+00 (2.6503e+00)\tAcc@1  37.50 ( 40.76)\tAcc@5  67.19 ( 67.44)\n",
      "Test: [200/782]\tTime  0.385 ( 0.645)\tLoss 2.6645e+00 (2.7045e+00)\tAcc@1  43.75 ( 40.62)\tAcc@5  62.50 ( 66.67)\n",
      "Test: [300/782]\tTime  0.345 ( 0.636)\tLoss 2.5870e+00 (2.7135e+00)\tAcc@1  39.06 ( 40.40)\tAcc@5  71.88 ( 66.55)\n",
      "Test: [400/782]\tTime  1.128 ( 0.633)\tLoss 2.8031e+00 (2.7180e+00)\tAcc@1  37.50 ( 40.29)\tAcc@5  64.06 ( 66.51)\n",
      "Test: [500/782]\tTime  0.313 ( 0.631)\tLoss 2.8581e+00 (2.7168e+00)\tAcc@1  39.06 ( 40.20)\tAcc@5  65.62 ( 66.53)\n",
      "Test: [600/782]\tTime  0.370 ( 0.632)\tLoss 2.5842e+00 (2.7170e+00)\tAcc@1  37.50 ( 40.16)\tAcc@5  75.00 ( 66.50)\n",
      "Test: [700/782]\tTime  0.305 ( 0.632)\tLoss 2.6750e+00 (2.7177e+00)\tAcc@1  45.31 ( 40.21)\tAcc@5  68.75 ( 66.48)\n",
      " * Acc@1 40.116 Acc@5 66.422\n",
      "lr: [0.4625625872291461]\n",
      "Epoch: [4][   0/5005]\tTime 14.090 (14.090)\tData 12.766 (12.766)\tLoss 2.889e+00 (2.889e+00)\tAcc@1  39.45 ( 39.45)\tAcc@5  62.11 ( 62.11)\n",
      "Epoch: [4][ 100/5005]\tTime  1.425 ( 2.424)\tData  0.201 ( 1.189)\tLoss 2.595e+00 (2.810e+00)\tAcc@1  43.75 ( 39.67)\tAcc@5  67.97 ( 64.81)\n",
      "Epoch: [4][ 200/5005]\tTime  1.321 ( 2.381)\tData  0.093 ( 1.160)\tLoss 2.903e+00 (2.816e+00)\tAcc@1  35.55 ( 39.59)\tAcc@5  60.94 ( 64.66)\n",
      "Epoch: [4][ 300/5005]\tTime  6.739 ( 2.351)\tData  5.493 ( 1.150)\tLoss 2.759e+00 (2.806e+00)\tAcc@1  39.06 ( 39.68)\tAcc@5  65.62 ( 64.82)\n",
      "Epoch: [4][ 400/5005]\tTime  1.447 ( 2.335)\tData  0.191 ( 1.143)\tLoss 2.704e+00 (2.797e+00)\tAcc@1  42.19 ( 39.75)\tAcc@5  67.19 ( 65.04)\n",
      "Epoch: [4][ 500/5005]\tTime  1.005 ( 2.329)\tData  0.176 ( 1.145)\tLoss 2.697e+00 (2.794e+00)\tAcc@1  39.45 ( 39.79)\tAcc@5  65.23 ( 65.09)\n",
      "Epoch: [4][ 600/5005]\tTime  1.362 ( 2.323)\tData  0.105 ( 1.151)\tLoss 2.630e+00 (2.792e+00)\tAcc@1  41.80 ( 39.82)\tAcc@5  68.75 ( 65.10)\n",
      "Epoch: [4][ 700/5005]\tTime  1.228 ( 2.324)\tData  0.089 ( 1.157)\tLoss 2.875e+00 (2.787e+00)\tAcc@1  38.28 ( 39.88)\tAcc@5  62.50 ( 65.11)\n",
      "Epoch: [4][ 800/5005]\tTime  4.542 ( 2.327)\tData  3.339 ( 1.168)\tLoss 2.811e+00 (2.788e+00)\tAcc@1  35.55 ( 39.86)\tAcc@5  64.84 ( 65.14)\n",
      "Epoch: [4][ 900/5005]\tTime  1.317 ( 2.328)\tData  0.209 ( 1.178)\tLoss 2.812e+00 (2.787e+00)\tAcc@1  42.19 ( 39.90)\tAcc@5  63.28 ( 65.12)\n",
      "Epoch: [4][1000/5005]\tTime  1.150 ( 2.329)\tData  0.075 ( 1.190)\tLoss 2.802e+00 (2.787e+00)\tAcc@1  38.28 ( 39.91)\tAcc@5  66.41 ( 65.13)\n",
      "Epoch: [4][1100/5005]\tTime  3.195 ( 2.333)\tData  2.399 ( 1.204)\tLoss 2.812e+00 (2.784e+00)\tAcc@1  40.23 ( 39.98)\tAcc@5  66.02 ( 65.20)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [4][1200/5005]\tTime  1.421 ( 2.342)\tData  0.235 ( 1.219)\tLoss 2.888e+00 (2.782e+00)\tAcc@1  38.67 ( 40.00)\tAcc@5  62.11 ( 65.21)\n",
      "Epoch: [4][1300/5005]\tTime  1.068 ( 2.348)\tData  0.085 ( 1.233)\tLoss 2.855e+00 (2.779e+00)\tAcc@1  33.20 ( 40.06)\tAcc@5  64.45 ( 65.26)\n",
      "Epoch: [4][1400/5005]\tTime  3.258 ( 2.357)\tData  2.581 ( 1.253)\tLoss 2.954e+00 (2.778e+00)\tAcc@1  32.81 ( 40.10)\tAcc@5  60.55 ( 65.25)\n",
      "Epoch: [4][1500/5005]\tTime  4.008 ( 2.368)\tData  3.079 ( 1.273)\tLoss 2.686e+00 (2.775e+00)\tAcc@1  40.62 ( 40.13)\tAcc@5  65.62 ( 65.30)\n",
      "Epoch: [4][1600/5005]\tTime  7.356 ( 2.378)\tData  6.619 ( 1.296)\tLoss 2.685e+00 (2.772e+00)\tAcc@1  39.84 ( 40.18)\tAcc@5  68.75 ( 65.36)\n",
      "Epoch: [4][1700/5005]\tTime  2.482 ( 2.384)\tData  1.885 ( 1.315)\tLoss 2.886e+00 (2.770e+00)\tAcc@1  39.06 ( 40.23)\tAcc@5  64.06 ( 65.39)\n",
      "Epoch: [4][1800/5005]\tTime  5.341 ( 2.398)\tData  4.473 ( 1.338)\tLoss 2.695e+00 (2.767e+00)\tAcc@1  42.97 ( 40.28)\tAcc@5  66.80 ( 65.43)\n",
      "Epoch: [4][1900/5005]\tTime  4.217 ( 2.408)\tData  3.122 ( 1.357)\tLoss 2.416e+00 (2.765e+00)\tAcc@1  46.88 ( 40.33)\tAcc@5  71.09 ( 65.48)\n",
      "Epoch: [4][2000/5005]\tTime  1.464 ( 2.413)\tData  0.611 ( 1.372)\tLoss 2.866e+00 (2.762e+00)\tAcc@1  42.97 ( 40.38)\tAcc@5  62.50 ( 65.52)\n",
      "Epoch: [4][2100/5005]\tTime  0.786 ( 2.423)\tData  0.088 ( 1.389)\tLoss 2.640e+00 (2.759e+00)\tAcc@1  44.53 ( 40.43)\tAcc@5  64.45 ( 65.56)\n",
      "Epoch: [4][2200/5005]\tTime  3.268 ( 2.431)\tData  2.211 ( 1.404)\tLoss 2.943e+00 (2.757e+00)\tAcc@1  41.02 ( 40.50)\tAcc@5  60.94 ( 65.62)\n",
      "Epoch: [4][2300/5005]\tTime  3.358 ( 2.436)\tData  2.571 ( 1.416)\tLoss 2.583e+00 (2.755e+00)\tAcc@1  39.06 ( 40.55)\tAcc@5  69.53 ( 65.65)\n",
      "Epoch: [4][2400/5005]\tTime  1.341 ( 2.444)\tData  0.273 ( 1.429)\tLoss 2.859e+00 (2.752e+00)\tAcc@1  36.33 ( 40.60)\tAcc@5  64.84 ( 65.70)\n",
      "Epoch: [4][2500/5005]\tTime  1.684 ( 2.448)\tData  0.908 ( 1.437)\tLoss 2.543e+00 (2.749e+00)\tAcc@1  44.53 ( 40.65)\tAcc@5  70.70 ( 65.75)\n",
      "Epoch: [4][2600/5005]\tTime  7.507 ( 2.455)\tData  6.254 ( 1.450)\tLoss 2.871e+00 (2.747e+00)\tAcc@1  35.94 ( 40.69)\tAcc@5  64.06 ( 65.77)\n",
      "Epoch: [4][2700/5005]\tTime  0.844 ( 2.459)\tData  0.082 ( 1.458)\tLoss 2.750e+00 (2.744e+00)\tAcc@1  39.84 ( 40.74)\tAcc@5  65.23 ( 65.82)\n",
      "Epoch: [4][2800/5005]\tTime  1.512 ( 2.464)\tData  0.731 ( 1.467)\tLoss 2.703e+00 (2.742e+00)\tAcc@1  42.19 ( 40.80)\tAcc@5  66.02 ( 65.87)\n",
      "Epoch: [4][2900/5005]\tTime  5.075 ( 2.471)\tData  4.088 ( 1.478)\tLoss 2.482e+00 (2.739e+00)\tAcc@1  49.61 ( 40.85)\tAcc@5  69.92 ( 65.92)\n",
      "Epoch: [4][3000/5005]\tTime  1.839 ( 2.477)\tData  1.043 ( 1.486)\tLoss 2.556e+00 (2.736e+00)\tAcc@1  45.31 ( 40.91)\tAcc@5  68.75 ( 65.98)\n",
      "Epoch: [4][3100/5005]\tTime  0.960 ( 2.483)\tData  0.087 ( 1.494)\tLoss 2.481e+00 (2.733e+00)\tAcc@1  48.44 ( 40.95)\tAcc@5  69.14 ( 66.03)\n",
      "Epoch: [4][3200/5005]\tTime  1.785 ( 2.489)\tData  0.969 ( 1.503)\tLoss 2.645e+00 (2.729e+00)\tAcc@1  40.23 ( 41.01)\tAcc@5  66.41 ( 66.09)\n",
      "Epoch: [4][3300/5005]\tTime  5.554 ( 2.492)\tData  4.887 ( 1.510)\tLoss 2.645e+00 (2.726e+00)\tAcc@1  44.92 ( 41.08)\tAcc@5  69.14 ( 66.14)\n",
      "Epoch: [4][3400/5005]\tTime  1.041 ( 2.495)\tData  0.074 ( 1.516)\tLoss 2.698e+00 (2.723e+00)\tAcc@1  37.11 ( 41.14)\tAcc@5  69.14 ( 66.19)\n",
      "Epoch: [4][3500/5005]\tTime  0.877 ( 2.500)\tData  0.058 ( 1.524)\tLoss 2.484e+00 (2.718e+00)\tAcc@1  45.70 ( 41.23)\tAcc@5  71.09 ( 66.28)\n",
      "Epoch: [4][3600/5005]\tTime  1.051 ( 2.503)\tData  0.151 ( 1.530)\tLoss 2.611e+00 (2.714e+00)\tAcc@1  42.19 ( 41.29)\tAcc@5  66.41 ( 66.33)\n",
      "Epoch: [4][3700/5005]\tTime  1.181 ( 2.506)\tData  0.181 ( 1.536)\tLoss 2.484e+00 (2.712e+00)\tAcc@1  43.75 ( 41.35)\tAcc@5  73.05 ( 66.38)\n",
      "Epoch: [4][3800/5005]\tTime  4.180 ( 2.509)\tData  3.408 ( 1.542)\tLoss 2.638e+00 (2.708e+00)\tAcc@1  42.97 ( 41.43)\tAcc@5  68.75 ( 66.44)\n",
      "Epoch: [4][3900/5005]\tTime  2.288 ( 2.510)\tData  1.574 ( 1.546)\tLoss 2.564e+00 (2.704e+00)\tAcc@1  41.02 ( 41.49)\tAcc@5  69.92 ( 66.51)\n",
      "Epoch: [4][4000/5005]\tTime  1.180 ( 2.513)\tData  0.222 ( 1.553)\tLoss 2.596e+00 (2.700e+00)\tAcc@1  41.02 ( 41.56)\tAcc@5  66.80 ( 66.57)\n",
      "Epoch: [4][4100/5005]\tTime  1.092 ( 2.515)\tData  0.063 ( 1.557)\tLoss 2.434e+00 (2.696e+00)\tAcc@1  44.92 ( 41.64)\tAcc@5  73.05 ( 66.63)\n",
      "Epoch: [4][4200/5005]\tTime  1.466 ( 2.517)\tData  0.519 ( 1.560)\tLoss 2.226e+00 (2.692e+00)\tAcc@1  46.48 ( 41.70)\tAcc@5  76.95 ( 66.70)\n",
      "Epoch: [4][4300/5005]\tTime  1.019 ( 2.520)\tData  0.108 ( 1.565)\tLoss 2.560e+00 (2.688e+00)\tAcc@1  42.97 ( 41.79)\tAcc@5  72.27 ( 66.77)\n",
      "Epoch: [4][4400/5005]\tTime  0.995 ( 2.522)\tData  0.086 ( 1.569)\tLoss 2.403e+00 (2.684e+00)\tAcc@1  47.66 ( 41.87)\tAcc@5  73.44 ( 66.84)\n",
      "Epoch: [4][4500/5005]\tTime  2.168 ( 2.525)\tData  1.321 ( 1.572)\tLoss 2.369e+00 (2.680e+00)\tAcc@1  47.66 ( 41.94)\tAcc@5  72.66 ( 66.91)\n",
      "Epoch: [4][4600/5005]\tTime  1.470 ( 2.526)\tData  0.226 ( 1.576)\tLoss 2.633e+00 (2.676e+00)\tAcc@1  42.19 ( 42.01)\tAcc@5  66.80 ( 66.96)\n",
      "Epoch: [4][4700/5005]\tTime  0.662 ( 2.529)\tData  0.068 ( 1.579)\tLoss 2.793e+00 (2.673e+00)\tAcc@1  41.02 ( 42.08)\tAcc@5  64.45 ( 67.02)\n",
      "Epoch: [4][4800/5005]\tTime  0.584 ( 2.530)\tData  0.092 ( 1.582)\tLoss 2.457e+00 (2.668e+00)\tAcc@1  47.27 ( 42.16)\tAcc@5  70.31 ( 67.10)\n",
      "Epoch: [4][4900/5005]\tTime  1.049 ( 2.532)\tData  0.102 ( 1.585)\tLoss 2.420e+00 (2.664e+00)\tAcc@1  44.14 ( 42.24)\tAcc@5  73.83 ( 67.16)\n",
      "Epoch: [4][5000/5005]\tTime  0.515 ( 2.533)\tData  0.068 ( 1.588)\tLoss 2.550e+00 (2.660e+00)\tAcc@1  45.70 ( 42.31)\tAcc@5  71.09 ( 67.22)\n",
      "Test: [  0/782]\tTime  5.212 ( 5.212)\tLoss 1.6142e+00 (1.6142e+00)\tAcc@1  64.06 ( 64.06)\tAcc@5  84.38 ( 84.38)\n",
      "Test: [100/782]\tTime  0.381 ( 0.669)\tLoss 2.1207e+00 (2.1403e+00)\tAcc@1  53.12 ( 51.05)\tAcc@5  73.44 ( 75.82)\n",
      "Test: [200/782]\tTime  0.244 ( 0.650)\tLoss 1.6878e+00 (2.1358e+00)\tAcc@1  59.38 ( 50.82)\tAcc@5  84.38 ( 75.96)\n",
      "Test: [300/782]\tTime  1.347 ( 0.638)\tLoss 2.3812e+00 (2.1475e+00)\tAcc@1  45.31 ( 50.51)\tAcc@5  71.88 ( 76.00)\n",
      "Test: [400/782]\tTime  1.876 ( 0.637)\tLoss 2.8347e+00 (2.1567e+00)\tAcc@1  39.06 ( 50.35)\tAcc@5  64.06 ( 75.93)\n",
      "Test: [500/782]\tTime  0.316 ( 0.635)\tLoss 2.2682e+00 (2.1557e+00)\tAcc@1  50.00 ( 50.25)\tAcc@5  75.00 ( 75.96)\n",
      "Test: [600/782]\tTime  1.633 ( 0.635)\tLoss 2.2560e+00 (2.1542e+00)\tAcc@1  48.44 ( 50.31)\tAcc@5  78.12 ( 76.01)\n",
      "Test: [700/782]\tTime  0.329 ( 0.634)\tLoss 2.0315e+00 (2.1542e+00)\tAcc@1  56.25 ( 50.31)\tAcc@5  81.25 ( 75.90)\n",
      " * Acc@1 50.316 Acc@5 75.818\n",
      "lr: [0.1334267085097146]\n",
      "Epoch: [5][   0/5005]\tTime 13.143 (13.143)\tData 11.699 (11.699)\tLoss 2.115e+00 (2.115e+00)\tAcc@1  53.12 ( 53.12)\tAcc@5  73.83 ( 73.83)\n",
      "Epoch: [5][ 100/5005]\tTime  1.304 ( 2.415)\tData  0.109 ( 1.244)\tLoss 2.258e+00 (2.383e+00)\tAcc@1  50.00 ( 47.32)\tAcc@5  75.39 ( 71.94)\n",
      "Epoch: [5][ 200/5005]\tTime  4.145 ( 2.370)\tData  3.097 ( 1.197)\tLoss 2.512e+00 (2.386e+00)\tAcc@1  48.05 ( 47.15)\tAcc@5  69.92 ( 71.77)\n",
      "Epoch: [5][ 300/5005]\tTime  7.570 ( 2.350)\tData  6.318 ( 1.189)\tLoss 1.892e+00 (2.378e+00)\tAcc@1  54.69 ( 47.21)\tAcc@5  78.91 ( 71.82)\n",
      "Epoch: [5][ 400/5005]\tTime  1.371 ( 2.336)\tData  0.185 ( 1.178)\tLoss 2.314e+00 (2.371e+00)\tAcc@1  48.83 ( 47.45)\tAcc@5  69.53 ( 71.89)\n",
      "Epoch: [5][ 500/5005]\tTime  2.688 ( 2.333)\tData  1.535 ( 1.185)\tLoss 2.209e+00 (2.373e+00)\tAcc@1  50.00 ( 47.52)\tAcc@5  71.09 ( 71.85)\n",
      "Epoch: [5][ 600/5005]\tTime  1.288 ( 2.332)\tData  0.164 ( 1.194)\tLoss 2.510e+00 (2.364e+00)\tAcc@1  42.97 ( 47.67)\tAcc@5  71.09 ( 72.06)\n",
      "Epoch: [5][ 700/5005]\tTime  4.364 ( 2.338)\tData  3.004 ( 1.206)\tLoss 2.602e+00 (2.361e+00)\tAcc@1  46.09 ( 47.72)\tAcc@5  68.75 ( 72.11)\n",
      "Epoch: [5][ 800/5005]\tTime  1.929 ( 2.336)\tData  1.400 ( 1.215)\tLoss 2.512e+00 (2.353e+00)\tAcc@1  44.53 ( 47.84)\tAcc@5  70.31 ( 72.22)\n",
      "Epoch: [5][ 900/5005]\tTime  1.371 ( 2.340)\tData  0.109 ( 1.229)\tLoss 2.140e+00 (2.347e+00)\tAcc@1  50.39 ( 47.97)\tAcc@5  74.22 ( 72.31)\n",
      "Epoch: [5][1000/5005]\tTime  1.435 ( 2.344)\tData  0.221 ( 1.242)\tLoss 2.397e+00 (2.340e+00)\tAcc@1  49.22 ( 48.12)\tAcc@5  72.66 ( 72.44)\n",
      "Epoch: [5][1100/5005]\tTime  1.102 ( 2.356)\tData  0.208 ( 1.263)\tLoss 2.203e+00 (2.333e+00)\tAcc@1  50.39 ( 48.21)\tAcc@5  71.88 ( 72.53)\n",
      "Epoch: [5][1200/5005]\tTime  0.975 ( 2.360)\tData  0.128 ( 1.279)\tLoss 2.194e+00 (2.327e+00)\tAcc@1  48.44 ( 48.32)\tAcc@5  74.22 ( 72.62)\n",
      "Epoch: [5][1300/5005]\tTime  4.427 ( 2.369)\tData  3.727 ( 1.297)\tLoss 2.076e+00 (2.322e+00)\tAcc@1  48.83 ( 48.41)\tAcc@5  77.34 ( 72.70)\n",
      "Epoch: [5][1400/5005]\tTime  0.962 ( 2.373)\tData  0.119 ( 1.316)\tLoss 2.329e+00 (2.319e+00)\tAcc@1  49.61 ( 48.46)\tAcc@5  69.92 ( 72.77)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [5][1500/5005]\tTime  1.430 ( 2.381)\tData  0.247 ( 1.333)\tLoss 2.309e+00 (2.314e+00)\tAcc@1  46.88 ( 48.55)\tAcc@5  74.61 ( 72.85)\n",
      "Epoch: [5][1600/5005]\tTime  7.641 ( 2.394)\tData  6.969 ( 1.354)\tLoss 2.315e+00 (2.308e+00)\tAcc@1  48.44 ( 48.67)\tAcc@5  73.44 ( 72.93)\n",
      "Epoch: [5][1700/5005]\tTime  1.690 ( 2.404)\tData  0.775 ( 1.373)\tLoss 2.095e+00 (2.303e+00)\tAcc@1  53.91 ( 48.80)\tAcc@5  75.00 ( 73.00)\n",
      "Epoch: [5][1800/5005]\tTime  0.864 ( 2.414)\tData  0.164 ( 1.391)\tLoss 2.226e+00 (2.296e+00)\tAcc@1  50.78 ( 48.92)\tAcc@5  75.39 ( 73.10)\n",
      "Epoch: [5][1900/5005]\tTime  2.658 ( 2.421)\tData  1.875 ( 1.407)\tLoss 2.220e+00 (2.291e+00)\tAcc@1  54.69 ( 49.06)\tAcc@5  71.88 ( 73.20)\n",
      "Epoch: [5][2000/5005]\tTime  1.254 ( 2.431)\tData  0.512 ( 1.424)\tLoss 2.313e+00 (2.284e+00)\tAcc@1  47.27 ( 49.17)\tAcc@5  71.48 ( 73.30)\n",
      "Epoch: [5][2100/5005]\tTime  1.157 ( 2.440)\tData  0.216 ( 1.437)\tLoss 2.203e+00 (2.279e+00)\tAcc@1  48.83 ( 49.26)\tAcc@5  74.22 ( 73.37)\n",
      "Epoch: [5][2200/5005]\tTime  1.041 ( 2.445)\tData  0.139 ( 1.448)\tLoss 2.298e+00 (2.273e+00)\tAcc@1  50.00 ( 49.39)\tAcc@5  72.27 ( 73.45)\n",
      "Epoch: [5][2300/5005]\tTime  0.912 ( 2.452)\tData  0.089 ( 1.460)\tLoss 2.091e+00 (2.268e+00)\tAcc@1  54.69 ( 49.50)\tAcc@5  80.08 ( 73.53)\n",
      "Epoch: [5][2400/5005]\tTime  0.971 ( 2.458)\tData  0.132 ( 1.470)\tLoss 2.097e+00 (2.261e+00)\tAcc@1  53.12 ( 49.61)\tAcc@5  77.73 ( 73.62)\n",
      "Epoch: [5][2500/5005]\tTime  1.203 ( 2.461)\tData  0.544 ( 1.478)\tLoss 2.153e+00 (2.255e+00)\tAcc@1  50.39 ( 49.75)\tAcc@5  73.83 ( 73.72)\n",
      "Epoch: [5][2600/5005]\tTime  0.788 ( 2.467)\tData  0.098 ( 1.486)\tLoss 2.214e+00 (2.251e+00)\tAcc@1  47.66 ( 49.84)\tAcc@5  74.61 ( 73.78)\n",
      "Epoch: [5][2700/5005]\tTime  4.782 ( 2.473)\tData  3.995 ( 1.495)\tLoss 2.036e+00 (2.246e+00)\tAcc@1  52.34 ( 49.95)\tAcc@5  76.56 ( 73.87)\n",
      "Epoch: [5][2800/5005]\tTime  2.757 ( 2.475)\tData  1.777 ( 1.502)\tLoss 2.143e+00 (2.240e+00)\tAcc@1  51.17 ( 50.06)\tAcc@5  73.44 ( 73.96)\n",
      "Epoch: [5][2900/5005]\tTime  1.272 ( 2.479)\tData  0.062 ( 1.508)\tLoss 1.963e+00 (2.234e+00)\tAcc@1  53.52 ( 50.17)\tAcc@5  76.95 ( 74.03)\n",
      "Epoch: [5][3000/5005]\tTime  3.771 ( 2.484)\tData  3.021 ( 1.515)\tLoss 2.049e+00 (2.228e+00)\tAcc@1  54.69 ( 50.29)\tAcc@5  76.17 ( 74.11)\n",
      "Epoch: [5][3100/5005]\tTime  3.971 ( 2.486)\tData  3.064 ( 1.520)\tLoss 2.378e+00 (2.223e+00)\tAcc@1  48.83 ( 50.41)\tAcc@5  72.66 ( 74.20)\n",
      "Epoch: [5][3200/5005]\tTime  1.239 ( 2.489)\tData  0.174 ( 1.525)\tLoss 1.979e+00 (2.217e+00)\tAcc@1  52.73 ( 50.54)\tAcc@5  75.78 ( 74.28)\n",
      "Epoch: [5][3300/5005]\tTime  1.253 ( 2.492)\tData  0.091 ( 1.531)\tLoss 2.079e+00 (2.212e+00)\tAcc@1  52.34 ( 50.65)\tAcc@5  72.66 ( 74.36)\n",
      "Epoch: [5][3400/5005]\tTime  0.938 ( 2.496)\tData  0.222 ( 1.537)\tLoss 2.058e+00 (2.207e+00)\tAcc@1  53.91 ( 50.76)\tAcc@5  77.34 ( 74.44)\n",
      "Epoch: [5][3500/5005]\tTime  1.195 ( 2.497)\tData  0.474 ( 1.540)\tLoss 2.069e+00 (2.202e+00)\tAcc@1  54.30 ( 50.85)\tAcc@5  72.27 ( 74.50)\n",
      "Epoch: [5][3600/5005]\tTime  6.608 ( 2.502)\tData  5.357 ( 1.546)\tLoss 2.209e+00 (2.198e+00)\tAcc@1  51.56 ( 50.95)\tAcc@5  74.61 ( 74.57)\n",
      "Epoch: [5][3700/5005]\tTime  9.334 ( 2.504)\tData  8.567 ( 1.550)\tLoss 2.047e+00 (2.192e+00)\tAcc@1  54.30 ( 51.05)\tAcc@5  80.08 ( 74.65)\n",
      "Epoch: [5][3800/5005]\tTime  1.268 ( 2.506)\tData  0.145 ( 1.552)\tLoss 2.187e+00 (2.187e+00)\tAcc@1  50.78 ( 51.15)\tAcc@5  75.78 ( 74.73)\n",
      "Epoch: [5][3900/5005]\tTime  0.956 ( 2.507)\tData  0.101 ( 1.555)\tLoss 1.775e+00 (2.183e+00)\tAcc@1  60.16 ( 51.24)\tAcc@5  82.03 ( 74.80)\n",
      "Epoch: [5][4000/5005]\tTime  8.996 ( 2.511)\tData  7.879 ( 1.561)\tLoss 2.010e+00 (2.178e+00)\tAcc@1  55.08 ( 51.33)\tAcc@5  78.12 ( 74.87)\n",
      "Epoch: [5][4100/5005]\tTime  1.279 ( 2.512)\tData  0.211 ( 1.563)\tLoss 1.754e+00 (2.174e+00)\tAcc@1  57.81 ( 51.41)\tAcc@5  80.47 ( 74.93)\n",
      "Epoch: [5][4200/5005]\tTime  1.096 ( 2.513)\tData  0.170 ( 1.566)\tLoss 2.027e+00 (2.170e+00)\tAcc@1  52.73 ( 51.49)\tAcc@5  77.73 ( 74.98)\n",
      "Epoch: [5][4300/5005]\tTime  5.953 ( 2.516)\tData  5.194 ( 1.570)\tLoss 1.919e+00 (2.166e+00)\tAcc@1  59.77 ( 51.58)\tAcc@5  81.25 ( 75.03)\n",
      "Epoch: [5][4400/5005]\tTime  2.005 ( 2.516)\tData  0.978 ( 1.571)\tLoss 1.954e+00 (2.162e+00)\tAcc@1  53.91 ( 51.66)\tAcc@5  83.20 ( 75.10)\n",
      "Epoch: [5][4500/5005]\tTime  0.958 ( 2.518)\tData  0.083 ( 1.574)\tLoss 1.914e+00 (2.159e+00)\tAcc@1  57.03 ( 51.74)\tAcc@5  77.73 ( 75.15)\n",
      "Epoch: [5][4600/5005]\tTime  2.276 ( 2.521)\tData  1.526 ( 1.579)\tLoss 1.925e+00 (2.155e+00)\tAcc@1  53.52 ( 51.81)\tAcc@5  78.12 ( 75.19)\n",
      "Epoch: [5][4700/5005]\tTime  2.115 ( 2.523)\tData  1.099 ( 1.581)\tLoss 1.691e+00 (2.152e+00)\tAcc@1  58.98 ( 51.89)\tAcc@5  82.42 ( 75.25)\n",
      "Epoch: [5][4800/5005]\tTime  1.058 ( 2.523)\tData  0.126 ( 1.583)\tLoss 2.165e+00 (2.149e+00)\tAcc@1  50.39 ( 51.95)\tAcc@5  76.95 ( 75.30)\n",
      "Epoch: [5][4900/5005]\tTime  2.953 ( 2.525)\tData  2.227 ( 1.586)\tLoss 1.878e+00 (2.145e+00)\tAcc@1  56.64 ( 52.03)\tAcc@5  79.30 ( 75.35)\n",
      "Epoch: [5][5000/5005]\tTime  1.034 ( 2.526)\tData  0.586 ( 1.589)\tLoss 1.839e+00 (2.142e+00)\tAcc@1  57.81 ( 52.10)\tAcc@5  76.95 ( 75.40)\n",
      "Test: [  0/782]\tTime  5.082 ( 5.082)\tLoss 1.5283e+00 (1.5283e+00)\tAcc@1  62.50 ( 62.50)\tAcc@5  84.38 ( 84.38)\n",
      "Test: [100/782]\tTime  0.404 ( 0.665)\tLoss 2.3269e+00 (1.6855e+00)\tAcc@1  48.44 ( 60.18)\tAcc@5  73.44 ( 82.53)\n",
      "Test: [200/782]\tTime  0.283 ( 0.647)\tLoss 1.4255e+00 (1.6920e+00)\tAcc@1  62.50 ( 59.60)\tAcc@5  87.50 ( 82.40)\n",
      "Test: [300/782]\tTime  0.355 ( 0.640)\tLoss 1.5145e+00 (1.6888e+00)\tAcc@1  64.06 ( 59.82)\tAcc@5  84.38 ( 82.51)\n",
      "Test: [400/782]\tTime  0.274 ( 0.635)\tLoss 2.1191e+00 (1.6795e+00)\tAcc@1  56.25 ( 59.94)\tAcc@5  81.25 ( 82.75)\n",
      "Test: [500/782]\tTime  0.078 ( 0.632)\tLoss 1.0301e+00 (1.6792e+00)\tAcc@1  71.88 ( 59.97)\tAcc@5  93.75 ( 82.79)\n",
      "Test: [600/782]\tTime  0.360 ( 0.635)\tLoss 1.4988e+00 (1.6739e+00)\tAcc@1  59.38 ( 60.12)\tAcc@5  92.19 ( 82.87)\n",
      "Test: [700/782]\tTime  1.275 ( 0.634)\tLoss 1.8844e+00 (1.6804e+00)\tAcc@1  57.81 ( 59.99)\tAcc@5  81.25 ( 82.78)\n",
      " * Acc@1 60.192 Acc@5 82.816\n",
      "lr: [4.005583818221238e-06]\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(START_EPOCH, EPOCHS):\n",
    "#    adjust_learning_rate(optimizer, epoch)\n",
    "\n",
    "    # train for one epoch\n",
    "    train(train_loader, model, criterion, optimizer, scheduler, epoch, device)\n",
    "\n",
    "    # evaluate on validation set\n",
    "    acc1 = validate(val_loader, model, criterion, device)\n",
    "\n",
    "    # remember best acc@1 and save checkpoint\n",
    "    is_best = acc1 > best_acc1\n",
    "    best_acc1 = max(acc1, best_acc1)\n",
    "\n",
    "\n",
    "    save_checkpoint({\n",
    "        'epoch': epoch + 1,\n",
    "        'arch': ARCH,\n",
    "        'state_dict': model.state_dict(),\n",
    "        'best_acc1': best_acc1,\n",
    "        'optimizer' : optimizer.state_dict(),\n",
    "        'scheduler' : scheduler.state_dict(),\n",
    "    }, is_best)\n",
    "    \n",
    "    #scheduler.step()\n",
    "    print('lr: ' + str(scheduler.get_last_lr()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "#from torchsummary import summary\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
